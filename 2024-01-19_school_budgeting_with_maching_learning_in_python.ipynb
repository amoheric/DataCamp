{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7c6063-3393-4a95-b9f6-e41bf3ceee0a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec3b43-ff5b-4cba-b0bc-75701ec7b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from typing import List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c133d10-081b-43a9-bf0f-5063bb1b0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85079ff5-7209-4ec2-a92a-ec9247162bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'D:\\users\\trenton\\Dropbox\\PythonProjects\\DataCamp\\functions')\n",
    "\n",
    "from multilabel import multilabel_train_test_split\n",
    "from score_sub import score_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace076f-4df9-4283-a268-ab8ca45405b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 700)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "pd.set_option('display.min_rows', 10)\n",
    "pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698fbde-4512-4417-97aa-bb18e8d8d17b",
   "metadata": {},
   "source": [
    "# Saving data from DataCamp to a local csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2bf183-f310-4383-9a58-4537e197982f",
   "metadata": {},
   "source": [
    "```python\n",
    "# output the data to a format that can be copied and pasted into notepad++\n",
    "# find all non and replace with np.nan\n",
    "# copy all of lists and replace ... in data = np.array([...])\n",
    "# print the columns names df.columns.tolist() and then create a variable in a notebook\n",
    "# create a dataframe with df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "# create the dataframe in the DataCamp console\n",
    "df = pd.read_csv('TrainingData.csv')  # do not specify index_col=0\n",
    "\n",
    "# print each row as a list with a comma at the end and then copy all of the lists into notepad++\n",
    "for r in df.to_numpy():\n",
    "    print(list(r), ',')\n",
    "\n",
    "# print the column names and copy them\n",
    "df.columns.tolist()\n",
    "\n",
    "# in jupyterlab\n",
    "data = np.array([...])  # replace ... with the cleaned lists from notepad++\n",
    "columns = ...  # pasted from DataCamp console\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "df.to_csv('TrainingData.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3731136-2d6e-4986-b2ae-34fa1744790c",
   "metadata": {},
   "source": [
    "# Exploring the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73a14f-5566-47e6-83f2-44da71584c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2024-01-19_school_budgeting_with_maching_learning_in_python/TrainingData.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aff791-1d21-427b-a658-1028258ad240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563556b0-7a29-4d6b-b556-e9ac8376a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f84ff-4bc2-49b6-8d96-8b41011bd643",
   "metadata": {},
   "source": [
    "## Summarize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffeeb68-9cba-42b1-9ea3-e5e514aa40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48c25f-deb4-411b-b8e3-cff93f10de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histogram\n",
    "plt.hist(df['FTE'].dropna(), ec='k')  # .dropna() isn't needed\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of %full-time \\n employee works')\n",
    "plt.xlabel('% of full-time')\n",
    "plt.ylabel('num employees')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae073d7-a2cf-4215-a253-efaad52c4cac",
   "metadata": {},
   "source": [
    "**The high variance in expenditures makes sense (some purchases are cheap some are expensive). Also, it looks like the FTE column is bimodal. That is, there are some part-time and some full-time employees.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4152c6-4d74-44dc-8764-34b7703bffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a4285-a60d-439e-a0bb-4d4e7cbdd00c",
   "metadata": {},
   "source": [
    "## Encode the Labels as Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed5b8b-46e5-4c58-8178-d0df14ba9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_td = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status']\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "df[LABELS_td] = df[LABELS_td].apply(categorize_label)\n",
    "print(df[LABELS_td].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f438ff-2132-487b-a4fc-47d2fc318245",
   "metadata": {},
   "source": [
    "## Counting Unique Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa046f05-270d-4ba9-8d7e-bbcf6c4edfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_labels = df[LABELS_td].apply(pd.Series.nunique)\n",
    "ax = num_unique_labels.plot(kind='bar', ylabel='Number of Unique Categories', xlabel='Column Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa6ec4b-6f90-4a2c-820e-0adaeca72b2f",
   "metadata": {},
   "source": [
    "## `def compute_log_loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe98be5-ce50-4caf-a513-1d2898cd8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_loss(predicted: Union[float, List[float]], actual: [int, List[int]], eps: float=1e-14) -> float:\n",
    "    \"\"\"\n",
    "    Computes the logarithmic loss between predicted and \n",
    "    actual when these are 1D arrays\n",
    "\n",
    "    :param predicted: The predicted probabilities as floats between 0-1\n",
    "    :param actual: The actual binary labels. Either 0 or 1\n",
    "    :param eps (optional): log(0) is inf, so we need to offset our\n",
    "                           precidted values slightly by eps from 0 to 1.\n",
    "    \"\"\"\n",
    "\n",
    "    predicted = np.clip(predicted, eps, 1 - eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted)\n",
    "                        + (1 - actual)\n",
    "                        * np.log(1 - predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23552926-321e-4bf9-9669-7068bc1e60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(0.85, 1), (0.99, 0), (0.51, 0)]\n",
    "\n",
    "for p, y in data:\n",
    "    print(compute_log_loss(p, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd275576-9af3-40e1-9d3a-f97860f3a316",
   "metadata": {},
   "source": [
    "**Lowest: A, Middle: C, Highest: B**\n",
    "\n",
    "**Of the two incorrect predictions, B will have a higher log loss because it is confident and wrong.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deea260-0aea-4c79-ba4e-b4815d7559fa",
   "metadata": {},
   "source": [
    "## Computing log loss with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e9931b-c32a-43e9-b7c2-53fd2010b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_confident = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.05, 0.05, 0.05, 0.05, 0.05])\n",
    "correct_not_confident = np.array([0.65, 0.65, 0.65, 0.65, 0.65, 0.35, 0.35, 0.35, 0.35, 0.35])\n",
    "wrong_not_confident = np.array([0.35, 0.35, 0.35, 0.35, 0.35, 0.65, 0.65, 0.65, 0.65, 0.65])\n",
    "wrong_confident = np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.95, 0.95, 0.95, 0.95, 0.95])\n",
    "actual_labels = np.array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cbe99d-ee7b-4b22-823a-5fb204bba355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print log loss for 1st case\n",
    "correct_confident_loss = compute_log_loss(correct_confident, actual_labels)\n",
    "print(\"Log loss, correct and confident: {}\".format(correct_confident_loss)) \n",
    "\n",
    "# Compute log loss for 2nd case\n",
    "correct_not_confident_loss = compute_log_loss(correct_not_confident, actual_labels)\n",
    "print(\"Log loss, correct and not confident: {}\".format(correct_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 3rd case\n",
    "wrong_not_confident_loss = compute_log_loss(wrong_not_confident, actual_labels)\n",
    "print(\"Log loss, wrong and not confident: {}\".format(wrong_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 4th case\n",
    "wrong_confident_loss = compute_log_loss(wrong_confident, actual_labels)\n",
    "print(\"Log loss, wrong and confident: {}\".format(wrong_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for actual labels\n",
    "actual_labels_loss = compute_log_loss(actual_labels, actual_labels)\n",
    "print(\"Log loss, actual labels: {}\".format(actual_labels_loss)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71d5d17-738b-4d7a-837c-5349702dc891",
   "metadata": {},
   "source": [
    "**Log loss penalizes highly confident wrong answers much more than any other type. This will be a good metric to use on your models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3842af-d395-4ab3-8d59-1ba934a936ef",
   "metadata": {},
   "source": [
    "# Creating a simple first model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e356e-6dd2-49e2-9a4a-decbd15701d5",
   "metadata": {},
   "source": [
    "## It's time to build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a257a0-cfb6-4acb-b6f6-a5555a644d61",
   "metadata": {},
   "source": [
    "```python\n",
    "data_to_train = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "labels_to_use = pd.get_dummies(df[LABELS])\n",
    "\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(data_to_train, labels_to_use, size=0.2, seed=123)\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "clf.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cdde3a-ed94-48f6-935e-718d56ecd376",
   "metadata": {},
   "source": [
    "## Setting up a train-test split in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20bd07-e061-42df-9d1b-b9828dcd499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS_td = df.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Create the new DataFrame: numeric_data_only\n",
    "numeric_data_only = df[NUMERIC_COLUMNS_td].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS_td])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c77394-64ca-4471-90a8-73cd2bd38f14",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41707c4f-006f-48fc-9847-1f6cd6789a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da410827-3364-45df-94ed-125da1a6750c",
   "metadata": {},
   "source": [
    "**The good news is that your workflow didn't cause any errors. The bad news is that your model scored the lowest possible accuracy: 0.0! But hey, you just threw away ALL of the text data in the budget. Later, you won't. Before you add the text data, let's see how the model does when scored by log loss.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae519164-080b-4993-a82e-80a218b78500",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc45dec5-f913-47f5-94aa-1a8b1fbcdcda",
   "metadata": {},
   "source": [
    "```python\n",
    "houldout = pd.read_csv('HoldoutData.csv', index_col=0)\n",
    "holdout = holdout[NUMERIC_COLUMNS].fillna(-1000)\n",
    "predictions = clf.predict_proba(holdout)\n",
    "```\n",
    "\n",
    "- Using `.predict()`\n",
    "  - would result in an output of 0 or 1\n",
    "  - Log loss penalized being confident and wrong\n",
    "  - Worse performance compared to `.predict_proba()`\n",
    "\n",
    "- Format and submit predictions\n",
    "```python\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS], prefix_sep='__').columns, index=houldout.index, data=predictions)\n",
    "prediction_df.to_csv('predictions.csv')\n",
    "score = score_submission(pred_path='predictions.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a60c0-2f7f-479e-81de-a7dffaf8515b",
   "metadata": {},
   "source": [
    "## Use your model to predict values on holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f53fd-8846-4a21-9605-90ca91ca08f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit it to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Load the holdout data: holdout\n",
    "holdout = pd.read_csv('data/2024-01-19_school_budgeting_with_maching_learning_in_python/HoldoutData.csv', index_col=0)\n",
    "\n",
    "# Generate predictions: predictions\n",
    "NUMERIC_COLUMNS_hd = holdout.select_dtypes(include='number').columns\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS_hd].fillna(-1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f6251-2ebf-403c-9e64-6192cf7ea705",
   "metadata": {},
   "source": [
    "## Writing out your results to a csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f822a-ed43-4139-ada1-390c9fab0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format predictions in DataFrame: prediction_df\n",
    "# pd.get_dummies(df[LABELS], ...) is correctly using df, not holdout\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS_td], prefix_sep='__').columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('data/2024-01-19_school_budgeting_with_maching_learning_in_python/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ce94e-6704-40d2-a91f-5676f30a6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires functions and variables from https://goodboychan.github.io/python/datacamp/machine_learning/2020/06/05/01-School-Budgeting-with-Machine-Learning-in-Python.html\n",
    "# BOX_PLOTS_COLUMN_INDICES, def _multi_multi_log_loss, and def score_submissio\n",
    "\n",
    "# Submit the predictions for scoring: score\n",
    "score = score_submission(pred_path='data/2024-01-19_school_budgeting_with_maching_learning_in_python/predictions.csv', holdout_path='data/2024-01-19_school_budgeting_with_maching_learning_in_python/TestSetLabelsSample.csv')\n",
    "\n",
    "# Print score\n",
    "print('Your model, trained with numeric data only, yields logloss score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68f7382-5f4b-4f01-a69a-dda406e6b18d",
   "metadata": {},
   "source": [
    "**Even though your basic model scored 0.0 accuracy, it nevertheless performs better than the benchmark score of 2.0455. You've now got the basics down and have made a first pass at this complicated supervised learning problem. It's time to step up your game and incorporate the text data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a52a4e-4b36-4977-81a0-74ebae25a8af",
   "metadata": {},
   "source": [
    "## A very brief introduction to NLP\n",
    "\n",
    "- Data for NLP:\n",
    "  - Text, documents, speech, ...\n",
    "- Tokenization\n",
    "  - Splitting a string into segments\n",
    "  - Store segments as list\n",
    "- Example: \"Natural Language Processing\"\n",
    "  - ['Natural', 'Language', 'Processing']\n",
    "\n",
    "- Tokenize on whitespace\n",
    "  - Petro-vend fuel and fluids\n",
    "    - Petro-vend | fuel | and | fluids\n",
    "- Tokenize on whitespace and punctuation\n",
    "  - Petro | vend | fuel | and | fluids\n",
    " \n",
    "- Bag of words representation\n",
    "  - Count the umber of times a particular token appears\n",
    "  - 'Bag of words'\n",
    "    - Count the number of times a word was pulled out of the bag\n",
    "- The approach discards information about word order\n",
    "  - 'Red, not blue' is the same as 'blue, not red'\n",
    " \n",
    "- 1-gram, 2-gram, ..., n-gram\n",
    "  - ![][1]\n",
    " \n",
    "[1]: https://raw.githubusercontent.com/trenton3983/DataCamp/master/Images/2024-01-19_school_budgeting_with_maching_learning_in_python/sb01.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26493578-8b50-4d8b-b5d9-70cf54c38f8e",
   "metadata": {},
   "source": [
    "## Tokenizating text\n",
    "\n",
    "- 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7658c31c-bb85-4322-b400-cb3d19c6fedf",
   "metadata": {},
   "source": [
    "## Testing your NLP credentials with n-grams\n",
    "\n",
    "- 12 - The number of `1-grams + 2-grams + 3-grams` is `5 + 4 + 3 = 12`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda3cb6-c027-42da-815b-de5c1b5bfe8a",
   "metadata": {},
   "source": [
    "## Representing text numerically\n",
    "\n",
    "**Scikit-learn tools for bag-of-words**\n",
    "\n",
    "- `CountVectorizer()`\n",
    "  - Tokenizes all the strings\n",
    "  - Builds a 'vocabulary'\n",
    "  - Counts the occurrences of each token in the vocabulary\n",
    " \n",
    "**Using `CountVectorizer() on a column of main dataset**\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import CountVecotrizer\n",
    "\n",
    "TOKENS_BASIC = '\\\\\\\\S+(?=\\\\\\\\s+)'\n",
    "df.Program_Description.fillna('', inplace=True)\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "vec_basic.fit(df.Program_Description)\n",
    "msg = 'There are {} token in Program_Desction if tokean are any non-whitespace'\n",
    "print(msg.format(len(vec_basic.get_feature_names())))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c900a0-2c4e-4aab-b89c-f6ab32b49a50",
   "metadata": {},
   "source": [
    "## Creating a bag-of-words in scikit-learn\r\n",
    "\r\n",
    "In this exercise, you'll study the effects of tokenizing in different ways by comparing the bag-of-words representations resulting from different token patterns.\r\n",
    "\r\n",
    "You will focus on one feature only, the `Position_Extra` column, which describes any additional information not captured by the `Position_Type` label.\r\n",
    "\r\n",
    "For example, in the Shell you can check out the budget item in row 8960 of the data using `df.loc[8960]`. Looking at the output reveals that this `Object_Description` is overtime pay. For who? The Position Type is merely \"other\", but the Position Extra elaborates: \"BUS DRIVER\". Explore the column further to see more instances. It has a lot of NaN values.\r\n",
    "\r\n",
    "Your task is to turn the raw text in this column into a bag-of-words representation by creating tokens that contain only alphanumeric characters.\r\n",
    "\r\n",
    "For comparison purposes, the first 15 tokens of `vec_basic`, which splits `df.Position_Extra` into tokens when it encounters only whitespace characters, have been printed along with the length of the representation.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Import `CountVectorizer` from `sklearn.feature_extraction.text`.\r\n",
    "- Fill missing values in `df.Position_Extra` using `.fillna('')` to replace NaNs with empty strings. Specify the additional keyword argument `inplace=True` so that you don't have to assign the result back to `df`.\r\n",
    "- Instantiate the `CountVectorizer` as `vec_alphanumeric` by specifying the `token_pattern` to be `TOKENS_ALPHANUMERIC`.\r\n",
    "- Fit `vec_alphanumeric` to `df.Position_Extra`.\r\n",
    "- Hit submit to see the `len` of the fitted representation as well as the first 15 elements, and compare to `vec_basic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529766f-ddf4-4c1a-856a-3e9244c7f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "df.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names_out())))\n",
    "print(vec_alphanumeric.get_feature_names_out()[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140f45f-e334-4675-9474-6b649752bc8b",
   "metadata": {},
   "source": [
    "**Treating only alpha-numeric characters as tokens gives you a smaller number of more meaningful tokens.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aba1af-baa2-4e3b-a86b-879b10e9bc68",
   "metadata": {},
   "source": [
    "## Combining text columns for tokenization\r\n",
    "\r\n",
    "In order to get a bag-of-words representation for all the text data in our DataFrame, you must first convert the text data in each row of the DataFrame into a single string.\r\n",
    "\r\n",
    "In the previous exercise, this wasn't necessary because you only looked at one column of data, so each row was already just a single string. `CountVectorizer` expects each row to just be a single string, so in order to use all of the text columns, you'll need a method to turn a list of strings into a single string.\r\n",
    "\r\n",
    "In this exercise, you'll complete the function definition `combine_text_columns()`. When completed, this function will convert all training text data in your DataFrame to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the `.fit_transform()` method.\r\n",
    "\r\n",
    "Note that the function uses `NUMERIC_COLUMNS` and `LABELS` to determine which columns to drop. These lists have been loaded into the workspace.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Use the `.drop()` method on `data_frame` with `to_drop` and `axis=` as arguments to drop the non-text data. Save the result as `text_data`.\r\n",
    "- Fill in missing values (inplace) in `text_data` with blanks (\"\"), using the `.fillna()` method.\r\n",
    "- Complete the `.apply()` method by writing a lambda function that uses the `.join()` method to join all the items in a row with a space in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce88b5-901a-4d35-a0d6-28d1fe57f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame: pd.DataFrame, to_drop: list=NUMERIC_COLUMNS_td + LABELS_td) -> pd.Series:\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna('', inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba63d58-a5d9-4334-b33b-571ca73f9851",
   "metadata": {},
   "source": [
    "## What's in a token?\r\n",
    "\r\n",
    "Now you will use `combine_text_columns` to convert all training text data in your DataFrame to a single vector that can be passed to the vectorizer object and made into a bag-of-words using the `.fit_transform()` method.\r\n",
    "\r\n",
    "You'll compare the effect of tokenizing using any non-whitespace characters as a token and using only alphanumeric characters as a token.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Import `CountVectorizer` from `sklearn.feature_extraction.text`.\r\n",
    "- Instantiate `vec_basic` and `vec_alphanumeric` using, respectively, the `TOKENS_BASIC` and `TOKENS_ALPHANUMERIC` patterns.\r\n",
    "- Create the text vector by using the `combine_text_columns()` function on `df`.\r\n",
    "- Using the `.fit_transform()` method with `text_vector`, fit and transform first `vec_basic` and then `vec_alphanumeric`. Print the number of tokens they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b92ae-b23b-4b44-89ec-8ce65c364652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the basic token pattern\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names_out())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names_out())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f1006-ef42-4a30-8ef7-d8c4946b2fda",
   "metadata": {},
   "source": [
    "**Notice that tokenizing on alpha-numeric tokens reduced the number of tokens, just as in the last exercise. We'll keep this in mind when building a better model with the Pipeline object next.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a8962-1e6f-4fa1-b4cd-ed2b48f410c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
