{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7c6063-3393-4a95-b9f6-e41bf3ceee0a",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "- DataCamp package versions vs. local versions:\n",
    "  - `sklearn v0.20.4` vs. `1.3.2`\n",
    "  - `numpy v1.17.4` vs. `1.26.3`\n",
    "  - `pandas v0.24.2` vs. `2.1.4`\n",
    "  - `matplotlib v3.1.2` vs. `3.8.1`\n",
    "  - `seaborn n/a` vs. `0.13.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efec3b43-ff5b-4cba-b0bc-75701ec7b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from typing import List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c133d10-081b-43a9-bf0f-5063bb1b0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85079ff5-7209-4ec2-a92a-ec9247162bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'D:\\users\\trenton\\Dropbox\\PythonProjects\\DataCamp\\functions')\n",
    "\n",
    "from multilabel import multilabel_train_test_split\n",
    "from score_sub import score_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ace076f-4df9-4283-a268-ab8ca45405b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 700)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "pd.set_option('display.min_rows', 10)\n",
    "pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698fbde-4512-4417-97aa-bb18e8d8d17b",
   "metadata": {},
   "source": [
    "# Saving data from DataCamp to a local csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2bf183-f310-4383-9a58-4537e197982f",
   "metadata": {},
   "source": [
    "```python\n",
    "# output the data to a format that can be copied and pasted into notepad++\n",
    "# find all non and replace with np.nan\n",
    "# copy all of lists and replace ... in data = np.array([...])\n",
    "# print the columns names df.columns.tolist() and then create a variable in a notebook\n",
    "# create a dataframe with df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "# create the dataframe in the DataCamp console\n",
    "df = pd.read_csv('TrainingData.csv')  # do not specify index_col=0\n",
    "\n",
    "# print each row as a list with a comma at the end and then copy all of the lists into notepad++\n",
    "for r in df.to_numpy():\n",
    "    print(list(r), ',')\n",
    "\n",
    "# print the column names and copy them\n",
    "df.columns.tolist()\n",
    "\n",
    "# in jupyterlab\n",
    "data = np.array([...])  # replace ... with the cleaned lists from notepad++\n",
    "columns = ...  # pasted from DataCamp console\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "df.to_csv('TrainingData.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3731136-2d6e-4986-b2ae-34fa1744790c",
   "metadata": {},
   "source": [
    "# Exploring the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f73a14f-5566-47e6-83f2-44da71584c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2024-01-19_school_budgeting_with_machine_learning_in_python/TrainingData.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3aff791-1d21-427b-a658-1028258ad240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>Text_2</th>\n",
       "      <th>SubFund_Description</th>\n",
       "      <th>Job_Title_Description</th>\n",
       "      <th>Text_3</th>\n",
       "      <th>Text_4</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>Supplemental *</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Operation and Maintenp.nance of Plant Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Certificated Salaries And Wages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Care and Upkeep of Building Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8291.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n",
       "      <td>TITLE I CARRYOVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Student Transportation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Shared Services</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Other Non-Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>REPAIR AND MAINTENANCE SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUPIL TRANSPORTATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMIN. SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STUDENT TRANSPORT SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>618.29</td>\n",
       "      <td>PUPIL TRANSPORTATION</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>Personal Services - Teachers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCHER 5TH GRADE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular Instruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>49768.82</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>General Supplies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General Supplies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>Instruction And Curriculum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>\"Title I, Part A Schoolwide Activities Related...</td>\n",
       "      <td>General Operating Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>Supplies and Materials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Community Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplies And Materials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other Community Services *</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2304.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n",
       "      <td>TITLE I PI+HOMELESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Function          Use          Sharing   Reporting  \\\n",
       "198                 NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "209   Student Transportation     NO_LABEL  Shared Services  Non-School   \n",
       "750     Teacher Compensation  Instruction  School Reported      School   \n",
       "931                 NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "1524                NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "\n",
       "     Student_Type Position_Type               Object_Type     Pre_K  \\\n",
       "198      NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "209      NO_LABEL      NO_LABEL    Other Non-Compensation  NO_LABEL   \n",
       "750   Unspecified       Teacher  Base Salary/Compensation  Non PreK   \n",
       "931      NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "1524     NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "\n",
       "       Operating_Status               Object_Description Text_2  \\\n",
       "198       Non-Operating                   Supplemental *    NaN   \n",
       "209   PreK-12 Operating  REPAIR AND MAINTENANCE SERVICES    NaN   \n",
       "750   PreK-12 Operating     Personal Services - Teachers    NaN   \n",
       "931       Non-Operating                 General Supplies    NaN   \n",
       "1524      Non-Operating           Supplies and Materials    NaN   \n",
       "\n",
       "                                 SubFund_Description Job_Title_Description  \\\n",
       "198   Operation and Maintenp.nance of Plant Services                   NaN   \n",
       "209                             PUPIL TRANSPORTATION                   NaN   \n",
       "750                                              NaN       TCHER 5TH GRADE   \n",
       "931                                              NaN                   NaN   \n",
       "1524                              Community Services                   NaN   \n",
       "\n",
       "     Text_3               Text_4               Sub_Object_Description  \\\n",
       "198     NaN                  NaN  Non-Certificated Salaries And Wages   \n",
       "209     NaN                  NaN                                  NaN   \n",
       "750     NaN  Regular Instruction                                  NaN   \n",
       "931     NaN                  NaN                     General Supplies   \n",
       "1524    NaN                  NaN               Supplies And Materials   \n",
       "\n",
       "     Location_Description  FTE                  Function_Description  \\\n",
       "198                   NaN  NaN  Care and Upkeep of Building Services   \n",
       "209       ADMIN. SERVICES  NaN             STUDENT TRANSPORT SERVICE   \n",
       "750                   NaN  1.0                                   NaN   \n",
       "931                   NaN  NaN                           Instruction   \n",
       "1524                  NaN  NaN            Other Community Services *   \n",
       "\n",
       "          Facility_or_Department Position_Extra     Total  \\\n",
       "198                          NaN            NaN  -8291.86   \n",
       "209                          NaN            NaN    618.29   \n",
       "750                          NaN        TEACHER  49768.82   \n",
       "931   Instruction And Curriculum            NaN     -1.02   \n",
       "1524                         NaN            NaN   2304.43   \n",
       "\n",
       "                                    Program_Description  \\\n",
       "198                                                 NaN   \n",
       "209                                PUPIL TRANSPORTATION   \n",
       "750                               Instruction - Regular   \n",
       "931   \"Title I, Part A Schoolwide Activities Related...   \n",
       "1524                                                NaN   \n",
       "\n",
       "                                       Fund_Description                Text_1  \n",
       "198   Title I - Disadvantaged Children/Targeted Assi...    TITLE I CARRYOVER   \n",
       "209                                        General Fund                   NaN  \n",
       "750                              General Purpose School                   NaN  \n",
       "931                              General Operating Fund                   NaN  \n",
       "1524  Title I - Disadvantaged Children/Targeted Assi...   TITLE I PI+HOMELESS  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "563556b0-7a29-4d6b-b556-e9ac8376a9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1560 entries, 198 to 101861\n",
      "Data columns (total 25 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Function                1560 non-null   object \n",
      " 1   Use                     1560 non-null   object \n",
      " 2   Sharing                 1560 non-null   object \n",
      " 3   Reporting               1560 non-null   object \n",
      " 4   Student_Type            1560 non-null   object \n",
      " 5   Position_Type           1560 non-null   object \n",
      " 6   Object_Type             1560 non-null   object \n",
      " 7   Pre_K                   1560 non-null   object \n",
      " 8   Operating_Status        1560 non-null   object \n",
      " 9   Object_Description      1461 non-null   object \n",
      " 10  Text_2                  382 non-null    object \n",
      " 11  SubFund_Description     1183 non-null   object \n",
      " 12  Job_Title_Description   1131 non-null   object \n",
      " 13  Text_3                  296 non-null    object \n",
      " 14  Text_4                  193 non-null    object \n",
      " 15  Sub_Object_Description  364 non-null    object \n",
      " 16  Location_Description    874 non-null    object \n",
      " 17  FTE                     449 non-null    float64\n",
      " 18  Function_Description    1340 non-null   object \n",
      " 19  Facility_or_Department  252 non-null    object \n",
      " 20  Position_Extra          1026 non-null   object \n",
      " 21  Total                   1542 non-null   float64\n",
      " 22  Program_Description     1192 non-null   object \n",
      " 23  Fund_Description        819 non-null    object \n",
      " 24  Text_1                  1132 non-null   object \n",
      "dtypes: float64(2), object(23)\n",
      "memory usage: 316.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f84ff-4bc2-49b6-8d96-8b41011bd643",
   "metadata": {},
   "source": [
    "## Summarize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ffeeb68-9cba-42b1-9ea3-e5e514aa40a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTE</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>449.000000</td>\n",
       "      <td>1.542000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.493532</td>\n",
       "      <td>1.446867e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.452844</td>\n",
       "      <td>7.916752e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.002369</td>\n",
       "      <td>-1.044084e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.004310</td>\n",
       "      <td>1.108111e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.440000</td>\n",
       "      <td>7.060299e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.347760e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.047222</td>\n",
       "      <td>1.367500e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FTE         Total\n",
       "count  449.000000  1.542000e+03\n",
       "mean     0.493532  1.446867e+04\n",
       "std      0.452844  7.916752e+04\n",
       "min     -0.002369 -1.044084e+06\n",
       "25%      0.004310  1.108111e+02\n",
       "50%      0.440000  7.060299e+02\n",
       "75%      1.000000  5.347760e+03\n",
       "max      1.047222  1.367500e+06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e48c25f-deb4-411b-b8e3-cff93f10de68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHWCAYAAACR5EiaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAABKkUlEQVR4nO3deVhXZf7/8ddHVkVEAWVRxCV33HINK3FJJbVySdu1rGwZ12ySshGbUrM0S7OacmvUYsqlvuGoaK5p5V4umRmKpojggojiwv37wx+f6SOgftg5PR/Xda7Lc5/7nPM+txQvz2ozxhgBAABYVJniLgAAAKAwEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXaAPJozZ45sNpt98vT0VGBgoDp06KAJEyYoKSkp2zrR0dGy2WxO7Sc9PV3R0dFas2aNU+vltK8aNWqoR48eTm3nRhYsWKCpU6fmuMxmsyk6OrpA91fQVq1apZYtW8rLy0s2m01LlizJsd+FCxf0/PPPq3LlyqpWrZpee+01XfsC+kOHDql8+fJatWpVjtuIiYlRo0aNVLZsWdlsNu3YscOpWq8dzzVr1shms93Uz8bGjRsVHR2t06dPZ1sWERGhiIgIp2oBShPX4i4AKO1mz56t+vXr69KlS0pKStKGDRv05ptv6u2331ZMTIw6d+5s7/vkk0+qW7duTm0/PT1d48aNkySnfiHlZV95sWDBAu3atUvDhw/PtmzTpk2qVq1aodeQV8YY9evXT3Xr1tXXX38tLy8v1atXL8e+kyZN0qJFi/TBBx8oNTVVQ4YMUa1atfTII4/Y+zz77LPq06ePOnXqlG39EydO6NFHH1W3bt00Y8YMeXh4qG7duoV2bNfauHGjxo0bp4EDB6pixYoOy2bMmFFkdQDFgbAD5FNYWJhatmxpn+/Tp49GjBih22+/Xb1799b+/fsVEBAgSapWrVqh//JPT09XuXLlimRfN9K2bdti3f+NHD16VCdPnlSvXr1yDCh/Fhsbq6FDh6pv376SpO+//17ffPONPex8/vnn+vHHH/XLL7/kuP6vv/6qS5cu6ZFHHlH79u0L9kDyqWHDhsVdAlCouIwFFILq1atr8uTJOnv2rD766CN7e06Xlr799ltFRETIz89PZcuWVfXq1dWnTx+lp6fr4MGDqly5siRp3Lhx9ktmAwcOdNjetm3b1LdvX1WqVEm1a9fOdV9ZFi9erCZNmsjT01O1atXSe++957A86xLdwYMHHdqvvWwSERGh2NhYHTp0yOGSXpacLmPt2rVL9957rypVqiRPT081a9ZMc+fOzXE/n332mV555RUFBwerQoUK6ty5s/bt25f7wP/Jhg0b1KlTJ3l7e6tcuXIKDw9XbGysfXl0dLQ9DL700kuy2WyqUaNGrtu7cOGCvLy87PPly5fXhQsXJEmnT5/W8OHDNWXKFPn7+2dbd+DAgbr99tslSf3795fNZrOfpcvtEtLAgQOvW48zoqOj9eKLL0qSatasaf97+vPf459rOHjwoGw2m9566y29+eabqlGjhsqWLauIiAh7aBs9erSCg4Pl4+OjXr165XjZNiYmRrfddpu8vLxUvnx5de3aVdu3by+QYwKcQdgBCsndd98tFxcXrVu3Ltc+Bw8eVPfu3eXu7q5Zs2Zp2bJlmjhxory8vHTx4kUFBQVp2bJlkqRBgwZp06ZN2rRpk1599VWH7fTu3Vu33HKLvvjiC3344YfXrWvHjh0aPny4RowYocWLFys8PFzDhg3T22+/7fQxzpgxQ+3atVNgYKC9tk2bNuXaf9++fQoPD9fu3bv13nvvadGiRWrYsKEGDhyoSZMmZev/8ssv69ChQ/rkk0/0r3/9S/v371fPnj115cqV69a1du1adezYUWfOnNHMmTP12WefydvbWz179lRMTIykq5f5Fi1aJEkaMmSINm3apMWLF+e6zfDwcM2aNUuHDh3S7t27FRMTo/DwcEnS3//+dzVq1EiPPfZYjuu++uqrev/99yVJ48eP16ZNm4r00tGTTz6pIUOGSJIWLVpk/3u69dZbr7ve+++/r++++07vv/++PvnkE/3yyy/q2bOnBg0apBMnTmjWrFmaNGmSVq5cqSeffNJh3fHjx+vBBx9Uw4YN9Z///Ef//ve/dfbsWd1xxx3as2dPoR0rkBMuYwGFxMvLS/7+/jp69GiufbZu3aoLFy7orbfeUtOmTe3tDz30kP3PLVq0kHT1Elhul4UGDBhgv6/nRo4ePart27fb9xcZGamkpCT985//1HPPPady5crd1Hakq5c/KlasKA8Pj5u6ZBUdHa2LFy9q9erVCgkJkXQ1FJ4+fVrjxo3T4MGD5ePj47D9efPm2eddXFzUr18/bd68+br7Gz16tCpVqqQ1a9aofPnykqQePXqoWbNmGjVqlPr166dq1arp8uXLkq6eibtR/dHR0erZs6f9bMvdd9+tIUOGaP369Zo3b5527tyZ67q1a9e2XyqqU6dOkV/eq1atmqpXry5Jat68+U2fMapYsaKWLFmiMmWu/rs4OTlZw4cPV/369fXVV1/Z+/3yyy+aOnWqUlNTVaFCBR0+fFhjx47V3/72N4ezhnfddZfq1KmjcePG2UMnUBQ4swMUomuf1rlWs2bN5O7urqefflpz587V77//nqf99OnT56b7NmrUyCFYSVfDVWpqqrZt25an/d+sb7/9Vp06dbIHnSwDBw5Uenp6trNC99xzj8N8kyZNJF196ik3586d0w8//KC+ffvag450NSg9+uijOnLkyE1fCvuzgIAA/fDDD4qPj9cff/yh2NhYubi4aPDgwRozZozq1KmjhQsXqlGjRvL19VWPHj10+PBhp/eTH8YYXb582WHKj7vvvtsedCSpQYMGkqTu3bs79MtqT0hIkCQtX75cly9f1mOPPeZQi6enp9q3b+/0k4VAfhF2gEJy7tw5paSkKDg4ONc+tWvX1sqVK1WlShU9//zzql27tmrXrq13333XqX0FBQXddN/AwMBc21JSUpzar7NSUlJyrDVrjK7dv5+fn8O8h4eHJOn8+fO57uPUqVMyxji1n5uVdV9P1nYmTpyoMmXK6MUXX9Qvv/yihx9+WJMnT9aRI0fk7+/v8KRWUVi7dq3c3Nwcpmvvu3KGr6+vw7y7u/t127PuYTp+/LgkqVWrVtnqiYmJUXJycp5rAvKCy1hAIYmNjdWVK1du+Lj4HXfcoTvuuENXrlzRli1bNG3aNA0fPlwBAQF64IEHbmpfzry7JzExMde2rHDh6ekpScrIyHDol99fUn5+fjp27Fi29qxLfTnd3OusSpUqqUyZMoW+n3379mnixIlauXKl3NzctHLlSjVq1Mj+uP/IkSPVtGlTpaWlOZxhupanp6fOnDmTrT0vY92iRQtt3rzZoe16YbuwZI3vl19+qdDQ0CLfP3AtzuwAhSAhIUGjRo2Sj4+PBg8efFPruLi4qE2bNvYbWbMuKd3M2Qxn7N69O9v9JQsWLJC3t7f9htWsezp++uknh35ff/11tu15eHjcdG2dOnXSt99+m+0+pk8//VTlypUrkHtZvLy81KZNGy1atMihrszMTM2bN0/VqlUrkPfbDB48WAMHDrTfpGyM0blz5+zL09LS7O3XU6NGDf36668OwTIlJUUbN250uiZvb2+1bNnSYco661LQP0fX07VrV7m6uurAgQPZ6smagKLEmR0gn3bt2mW/JyEpKUnr16/X7Nmz5eLiosWLF9sfHc/Jhx9+qG+//Vbdu3dX9erVdeHCBc2aNUuS7C8j9Pb2VmhoqL766it16tRJvr6+8vf3z/NjycHBwbrnnnsUHR2toKAgzZs3T3FxcXrzzTftNye3atVK9erV06hRo3T58mVVqlRJixcv1oYNG7Jtr3HjxvaX7bVo0UJlypTJ9ZfZ2LFj9c0336hDhw76xz/+IV9fX82fP1+xsbGaNGmSw83J+TFhwgTddddd6tChg0aNGiV3d3fNmDFDu3bt0meffeb0W6yvNWvWLP36668ON+l26tRJI0aM0D/+8Q/dcccdGjt2rNq1aydvb+/rbuvRRx/VRx99pEceeURPPfWUUlJSNGnSJFWoUCFfNV6rcePGkqR3331XAwYMkJubm+rVq3fD+vKiRo0aeu211/TKK6/o999/V7du3VSpUiUdP35cP/74o7y8vG76hnqgQBgAeTJ79mwjyT65u7ubKlWqmPbt25vx48ebpKSkbOuMHTvW/Pk/u02bNplevXqZ0NBQ4+HhYfz8/Ez79u3N119/7bDeypUrTfPmzY2Hh4eRZAYMGOCwvRMnTtxwX8YYExoaarp3726+/PJL06hRI+Pu7m5q1KhhpkyZkm39X3/91XTp0sVUqFDBVK5c2QwZMsTExsYaSWb16tX2fidPnjR9+/Y1FStWNDabzWGfkszYsWMdtvvzzz+bnj17Gh8fH+Pu7m6aNm1qZs+e7dBn9erVRpL54osvHNrj4+ONpGz9c7J+/XrTsWNH4+XlZcqWLWvatm1r/u///i/H7b311ls33F6WpKQk4+vrm602Y4yZP3++qVOnjilfvry56667zO+//37DYzLGmLlz55oGDRoYT09P07BhQxMTE2MGDBhgQkNDHfpdO55Z2/zz38f1REVFmeDgYFOmTBmH9dq3b2/at29v75fbuOR2DFn/LWzevNmhfcmSJaZDhw6mQoUKxsPDw4SGhpq+ffualStX3lS9QEGxGXODc6wAAAClGPfsAAAASyPsAAAASyPsAAAASyPsAAAASyPsACgWOX0RHc6x2Wz629/+VtxlACUeYQcAAFgaYQcASpmieAsyYCWEHeAvIDU1VaNGjVLNmjXl7u6uqlWravjw4Q6fN5D+d1lk9uzZqlevnsqWLauWLVvq+++/lzFGb731lmrWrKny5curY8eO+u233xzWj4iIUFhYmNavX6+2bduqbNmyqlq1ql599VVduXLlhnXu2rVL9957rypVqiRPT081a9ZMc+fOtS9PS0tTxYoVc/wEx8GDB+Xi4qK33nrL3paYmKjBgwerWrVqcnd3V82aNTVu3LhsXwO/ePGiXn/9ddWvX18eHh6qXLmyHn/8cZ04ceK69cbGxspmszl8j2rhwoWy2WzZvgzepEkTh6/TX7hwQVFRUQ5/J88//7xOnz7tsF6NGjXUo0cPLVq0SM2bN5enp2eubx82xujll1+Wm5ubPv74Y0lXP5Px+uuv2/8+K1asqCZNmjj9sVmgVCvedxoCKGznzp0zzZo1M/7+/mbKlClm5cqV5t133zU+Pj6mY8eOJjMz095XkgkNDTXh4eFm0aJFZvHixaZu3brG19fXjBgxwtx7773mm2++MfPnzzcBAQGmSZMmDuu3b9/e+Pn5meDgYPPee++Z5cuXm6FDhxpJ5vnnn3eoS9e8DfiXX34x3t7epnbt2ubTTz81sbGx5sEHHzSSzJtvvmnvN2LECOPl5WVOnz7tsL0XX3zReHp6muTkZGOMMceOHTMhISEmNDTUfPTRR2blypXmn//8p/Hw8DADBw60r3flyhXTrVs34+XlZcaNG2fi4uLMJ598YqpWrWoaNmxo0tPTcx3bs2fPGjc3NzN+/Hh72zPPPGPKli1rvLy8zMWLF40xxhw/ftzYbDYzY8YMY4wxmZmZpmvXrsbV1dW8+uqrZsWKFebtt982Xl5epnnz5ubChQv27YWGhpqgoCBTq1YtM2vWLLN69Wrz448/2scwa1wvXLhgHnjgAePt7W3++9//2tefMGGCcXFxMWPHjjWrVq0yy5YtM1OnTjXR0dG5HhdgNYQdwOImTJhgypQpk+1V/l9++aWRZJYuXWpvk2QCAwNNWlqavW3JkiVGkmnWrJlDsJk6daqRZH766Sd7W/v27Y0k89VXXzns66mnnjJlypQxhw4dctjXn8POAw88YDw8PExCQoLDupGRkaZcuXL2cHPgwAFTpkwZ884779j7nD9/3vj5+ZnHH3/c3jZ48GBTvnx5h30aY8zbb79tJJndu3cbY4z57LPPjCSzcOFCh36bN282kuwBJTe333676dixo33+lltuMS+++KIpU6aMWbt2rTHm6mckJJlff/3VGGPMsmXLjCQzadIkh23FxMQYSeZf//qXvS00NNS4uLiYffv2Zdt3VthJSUkxt99+u6latarZsWOHQ58ePXqYZs2aXfcYAKvjMhZgcd98843CwsLUrFkz+wdLL1++rK5du8pms2nNmjUO/Tt06CAvLy/7fIMGDSRJkZGRDh/QzGo/dOiQw/re3t665557HNoeeughZWZmat26dbnW+e2336pTp04KCQlxaB84cKDS09O1adMmSVKtWrXUo0cPzZgxw/5F8QULFiglJcXhyaSsD44GBwc7HHdkZKQkae3atfZ+FStWVM+ePR36NWvWTIGBgdnG51qdOnXSd999p/Pnz+vQoUP67bff9MADD6hZs2aKi4uTJK1cuVLVq1dXnTp17MeadWx/dv/998vLy0urVq1yaG/SpEmuX2qPj4/XbbfdptTUVH3//fdq2rSpw/LWrVtr586deu6557R8+XKlpqZe93gAKyLsABZ3/Phx/fTTT3Jzc3OYvL29ZYxRcnKyQ39fX1+HeXd39+u2X7hwwaE9ICAgWw2BgYGSpJSUlFzrTElJUVBQULb24ODgbOsOGzZM+/fvt4eJ999/X7fddptuvfVWh+P+v//7v2zH3ahRI0myH/fx48d1+vRpubu7Z+ubmJiYbXyu1blzZ2VkZGjDhg2Ki4uTv7+/mjdvrs6dO2vlypWSpFWrVtm/Yp91LK6urqpcubLDtmw2mwIDA7ONU07jkuXHH3/Ur7/+qv79+6tatWrZlkdFRentt9/W999/r8jISPn5+alTp07asmXLdY8LsBLX4i4AQOHy9/dX2bJlNWvWrFyXF6Tjx49na0tMTJQk+fn55bqen5+fjh07lq396NGjkhzr7Nixo8LCwjR9+nSVL19e27Zt07x58xzW8/f3V5MmTfTGG2/kuL+sEOXv7y8/Pz8tW7Ysx37e3t651ixJbdq0Ufny5bVy5UodPHhQnTp1ks1mU6dOnTR58mRt3rxZCQkJDmHHz89Ply9f1okTJxwCjzFGiYmJatWqlcM+/nxG7Vr9+/dXYGCgXnnlFWVmZmrMmDEOy11dXTVy5EiNHDlSp0+f1sqVK/Xyyy+ra9euOnz4sMqVK3fd4wOsgLADWFyPHj00fvx4+fn5qWbNmoW+v7Nnz+rrr792uJS1YMEClSlTRnfeeWeu63Xq1EmLFy/W0aNH7UFEkj799FOVK1dObdu2deg/dOhQPfPMMzpz5owCAgJ0//33Oyzv0aOHli5dqtq1a6tSpUq57rdHjx76/PPPdeXKFbVp08bZw5Wbm5vuvPNOxcXF6fDhw5o4caIk6Y477pCrq6vGjBljDz9/PtZJkyZp3rx5GjFihL194cKFOnfunEPfmzFmzBh5e3trxIgROnfunCZMmJBjv4oVK6pv3776448/NHz4cB08eFANGzZ0+piB0oawA1jc8OHDtXDhQt15550aMWKEmjRposzMTCUkJGjFihV64YUX8vRLPjd+fn569tlnlZCQoLp162rp0qX6+OOP9eyzz6p69eq5rjd27Fj7fTb/+Mc/5Ovrq/nz5ys2NlaTJk2Sj4+PQ/9HHnlEUVFRWrduncaMGWO/rJbltddeU1xcnMLDwzV06FDVq1dPFy5c0MGDB7V06VJ9+OGHqlatmh544AHNnz9fd999t4YNG6bWrVvLzc1NR44c0erVq3XvvfeqV69e1z3mTp066YUXXpAk+xmcsmXLKjw8XCtWrFCTJk1UpUoVe/+77rpLXbt21UsvvaTU1FS1a9dOP/30k8aOHavmzZvr0UcfdWrMpauX9sqXL6+nn35aaWlpeu+992Sz2dSzZ0+FhYWpZcuWqly5sg4dOqSpU6cqNDTUfg8RYHnFfIM0gCKQlpZmxowZY+rVq2fc3d2Nj4+Pady4sRkxYoRJTEy091MOj4jHx8cbSeatt95yaF+9erWRZL744gt7W/v27U2jRo3MmjVrTMuWLY2Hh4cJCgoyL7/8srl06ZLD+rrmaSxjjPn5559Nz549jY+Pj3F3dzdNmzY1s2fPzvW4Bg4caFxdXc2RI0dyXH7ixAkzdOhQU7NmTePm5mZ8fX1NixYtzCuvvOLwxNmlS5fM22+/bZo2bWo8PT1N+fLlTf369c3gwYPN/v37c91/lp07dxpJpk6dOg7tb7zxhpFkRo4cmW2d8+fPm5deesmEhoYaNzc3ExQUZJ599llz6tQph36hoaGme/fuOe43p7+vzz77zLi6uprHH3/cXLlyxUyePNmEh4cbf39/4+7ubqpXr24GDRpkDh48eMPjAqzCZsz/f5wBAPIpIiJCycnJ2rVrV6Hv6+LFi6pRo4Zuv/12/ec//yn0/QEovbiMBaBUOXHihPbt26fZs2fr+PHjGj16dHGXBKCEI+wAKFViY2P1+OOPKygoSDNmzHB43BwAcsJlLAAAYGm8VBAAAFgaYQcAAFgaYQcAAFgaNyhLyszM1NGjR+Xt7X3d17IDAICSwxijs2fPKjg4WGXK5H7+hrCjq9/eufZLywAAoHQ4fPhwjh/CzULY0f8+9Hf48GFVqFChmKsBAAA3IzU1VSEhITf8YC9hR//7onCFChUIOwAAlDI3ugWFG5QBAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClFWvYWbdunXr27Kng4GDZbDYtWbLEYbnNZstxeuutt+x9IiIisi1/4IEHivhIAABASVWsYefcuXNq2rSppk+fnuPyY8eOOUyzZs2SzWZTnz59HPo99dRTDv0++uijoigfAACUAsX61fPIyEhFRkbmujwwMNBh/quvvlKHDh1Uq1Yth/Zy5cpl6wsAACAVc9hxxvHjxxUbG6u5c+dmWzZ//nzNmzdPAQEBioyM1NixY+Xt7Z3rtjIyMpSRkWGfT01NLZSaAQAoaAkJCUpOTi7uMpzi7++v6tWrF9v+S03YmTt3rry9vdW7d2+H9ocfflg1a9ZUYGCgdu3apaioKO3cuVNxcXG5bmvChAkaN25cYZcMAECBSkhIUL36DXThfHpxl+IUz7LltO+XvcUWeEpN2Jk1a5YefvhheXp6OrQ/9dRT9j+HhYWpTp06atmypbZt26Zbb701x21FRUVp5MiR9vnU1FSFhIQUTuEAABSQ5ORkXTifLr8eL8jNr3T83rqUclgp30xWcnIyYed61q9fr3379ikmJuaGfW+99Va5ublp//79uYYdDw8PeXh4FHSZAAAUCTe/EHkE3lLcZZQapSLszJw5Uy1atFDTpk1v2Hf37t26dOmSgoKCiqCyGyuN11al4r++CgBAQSnWsJOWlqbffvvNPh8fH68dO3bI19fX/os2NTVVX3zxhSZPnpxt/QMHDmj+/Pm6++675e/vrz179uiFF15Q8+bN1a5duyI7jtyU1murUvFfXwUAoKAUa9jZsmWLOnToYJ/Puo9mwIABmjNnjiTp888/lzFGDz74YLb13d3dtWrVKr377rtKS0tTSEiIunfvrrFjx8rFxaVIjuF6SuO1ValkXF8FAKCgFGvYiYiIkDHmun2efvppPf300zkuCwkJ0dq1awujtALFtVUAAIoP38YCAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWVqxhZ926derZs6eCg4Nls9m0ZMkSh+UDBw6UzWZzmNq2bevQJyMjQ0OGDJG/v7+8vLx0zz336MiRI0V4FAAAoCQr1rBz7tw5NW3aVNOnT8+1T7du3XTs2DH7tHTpUoflw4cP1+LFi/X5559rw4YNSktLU48ePXTlypXCLh8AAJQCrsW588jISEVGRl63j4eHhwIDA3NcdubMGc2cOVP//ve/1blzZ0nSvHnzFBISopUrV6pr164FXjMAAChdSvw9O2vWrFGVKlVUt25dPfXUU0pKSrIv27p1qy5duqQuXbrY24KDgxUWFqaNGzfmus2MjAylpqY6TAAAwJpKdNiJjIzU/Pnz9e2332ry5MnavHmzOnbsqIyMDElSYmKi3N3dValSJYf1AgIClJiYmOt2J0yYIB8fH/sUEhJSqMcBAACKT7FexrqR/v372/8cFhamli1bKjQ0VLGxserdu3eu6xljZLPZcl0eFRWlkSNH2udTU1MJPAAAWFSJPrNzraCgIIWGhmr//v2SpMDAQF28eFGnTp1y6JeUlKSAgIBct+Ph4aEKFSo4TAAAwJpKVdhJSUnR4cOHFRQUJElq0aKF3NzcFBcXZ+9z7Ngx7dq1S+Hh4cVVJgAAKEGK9TJWWlqafvvtN/t8fHy8duzYIV9fX/n6+io6Olp9+vRRUFCQDh48qJdffln+/v7q1auXJMnHx0eDBg3SCy+8ID8/P/n6+mrUqFFq3Lix/eksAADw11asYWfLli3q0KGDfT7rPpoBAwbogw8+0M8//6xPP/1Up0+fVlBQkDp06KCYmBh5e3vb13nnnXfk6uqqfv366fz58+rUqZPmzJkjFxeXIj8eAABQ8hRr2ImIiJAxJtfly5cvv+E2PD09NW3aNE2bNq0gSwMAABZRqu7ZAQAAcBZhBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWFqxhp1169apZ8+eCg4Ols1m05IlS+zLLl26pJdeekmNGzeWl5eXgoOD9dhjj+no0aMO24iIiJDNZnOYHnjggSI+EgAAUFIVa9g5d+6cmjZtqunTp2dblp6erm3btunVV1/Vtm3btGjRIv3666+65557svV96qmndOzYMfv00UcfFUX5AACgFHAtzp1HRkYqMjIyx2U+Pj6Ki4tzaJs2bZpat26thIQEVa9e3d5erlw5BQYGFmqtAACgdCpV9+ycOXNGNptNFStWdGifP3++/P391ahRI40aNUpnz5697nYyMjKUmprqMAEAAGsq1jM7zrhw4YJGjx6thx56SBUqVLC3P/zww6pZs6YCAwO1a9cuRUVFaefOndnOCv3ZhAkTNG7cuKIoGwAAFLNSEXYuXbqkBx54QJmZmZoxY4bDsqeeesr+57CwMNWpU0ctW7bUtm3bdOutt+a4vaioKI0cOdI+n5qaqpCQkMIpHgAAFKsSH3YuXbqkfv36KT4+Xt9++63DWZ2c3HrrrXJzc9P+/ftzDTseHh7y8PAojHIBAEAJU6LDTlbQ2b9/v1avXi0/P78brrN7925dunRJQUFBRVAhAAAo6Yo17KSlpem3336zz8fHx2vHjh3y9fVVcHCw+vbtq23btumbb77RlStXlJiYKEny9fWVu7u7Dhw4oPnz5+vuu++Wv7+/9uzZoxdeeEHNmzdXu3btiuuwAABACVKsYWfLli3q0KGDfT7rPpoBAwYoOjpaX3/9tSSpWbNmDuutXr1aERERcnd316pVq/Tuu+8qLS1NISEh6t69u8aOHSsXF5ciOw4AAFByFWvYiYiIkDEm1+XXWyZJISEhWrt2bUGXBQAALKRUvWcHAADAWYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgafkOO6mpqVqyZIn27t1bEPUAAAAUKKfDTr9+/TR9+nRJ0vnz59WyZUv169dPTZo00cKFCwu8QAAAgPxwOuysW7dOd9xxhyRp8eLFMsbo9OnTeu+99/T6668XeIEAAAD54XTYOXPmjHx9fSVJy5YtU58+fVSuXDl1795d+/fvL/ACAQAA8sPpsBMSEqJNmzbp3LlzWrZsmbp06SJJOnXqlDw9PQu8QAAAgPxw+ttYw4cP18MPP6zy5curevXqioiIkHT18lbjxo0Luj4AAIB8cTrsPPfcc2rdurUOHz6su+66S2XKXD05VKtWLe7ZAQAAJU6evnresmVLNWnSRPHx8apdu7ZcXV3VvXv3gq4NAAAg35y+Zyc9PV2DBg1SuXLl1KhRIyUkJEiShg4dqokTJxZ4gQAAAPnhdNiJiorSzp07tWbNGocbkjt37qyYmJgCLQ4AACC/nL6MtWTJEsXExKht27ay2Wz29oYNG+rAgQMFWhwAAEB+OX1m58SJE6pSpUq29nPnzjmEHwAAgJLA6bDTqlUrxcbG2uezAs7HH3+s2267reAqAwAAKABOX8aaMGGCunXrpj179ujy5ct69913tXv3bm3atElr164tjBoBAADyzOkzO+Hh4fruu++Unp6u2rVra8WKFQoICNCmTZvUokWLwqgRAAAgz/L0np3GjRtr7ty5BV0LAABAgXP6zI4kHThwQGPGjNFDDz2kpKQkSVc/Crp79+4CLQ4AACC/nA47a9euVePGjfXDDz9o4cKFSktLkyT99NNPGjt2bIEXCAAAkB9Oh53Ro0fr9ddfV1xcnNzd3e3tHTp00KZNmwq0OAAAgPxyOuz8/PPP6tWrV7b2ypUrKyUlpUCKAgAAKChOh52KFSvq2LFj2dq3b9+uqlWrFkhRAAAABcXpsPPQQw/ppZdeUmJiomw2mzIzM/Xdd99p1KhReuyxxwqjRgAAgDxzOuy88cYbql69uqpWraq0tDQ1bNhQd955p8LDwzVmzJjCqBEAACDPnH7Pjpubm+bPn6/XXntN27dvV2Zmppo3b646deoURn0AAAD54nTYWbNmjSIiIlS7dm3Vrl27MGoCAAAoME5fxurWrZtq166t119/XUeOHCmMmgAAAAqM02Hn6NGjGjZsmBYtWqQaNWqoa9eu+s9//qOLFy8WRn0AAAD54nTY8fX11dChQ7Vt2zZt2bJF9erV0/PPP6+goCANHTpUO3fuLIw6AQAA8iRP38bK0qxZM40ePVrPP/+8zp07p1mzZqlFixa64447+E4WAAAoEfIUdi5duqQvv/xSd999t0JDQ7V8+XJNnz5dx48fV3x8vEJCQnT//fcXdK0AAABOc/pprCFDhuizzz6TJD3yyCOaNGmSwsLC7Mu9vLw0ceJE1ahRo8CKBAAAyCunw86ePXs0bdo09enTx+FDoH8WHBys1atX57s4AACA/HI67KxaterGG3V1Vfv27fNUEAAAQEFyOuxI0oEDBzR16lTt3btXNptNDRo00LBhw3jJIAAAKHGcvkF5+fLlatiwoX788Uc1adJEYWFh+uGHH9SoUSPFxcU5ta1169apZ8+eCg4Ols1m05IlSxyWG2MUHR2t4OBglS1bVhEREdme8srIyNCQIUPk7+8vLy8v3XPPPbzsEAAA2DkddkaPHq0RI0bohx9+0JQpU/TOO+/ohx9+0PDhw/XSSy85ta1z586padOmmj59eo7LJ02apClTpmj69OnavHmzAgMDddddd+ns2bP2PsOHD9fixYv1+eefa8OGDUpLS1OPHj105coVZw8NAABYkNOXsfbu3av//Oc/2dqfeOIJTZ061altRUZGKjIyMsdlxhhNnTpVr7zyinr37i1Jmjt3rgICArRgwQINHjxYZ86c0cyZM/Xvf/9bnTt3liTNmzdPISEhWrlypbp27ercwQEAAMtx+sxO5cqVtWPHjmztO3bsUJUqVQqiJklSfHy8EhMT1aVLF3ubh4eH2rdvr40bN0qStm7dqkuXLjn0CQ4OVlhYmL1PTjIyMpSamuowAQAAa3L6zM5TTz2lp59+Wr///rvCw8Nls9m0YcMGvfnmm3rhhRcKrLDExERJUkBAgEN7QECADh06ZO/j7u6uSpUqZeuTtX5OJkyYoHHjxhVYrQAAoORyOuy8+uqr8vb21uTJkxUVFSXp6tmU6OhoDR06tMALtNlsDvPGmGxt17pRn6ioKI0cOdI+n5qaqpCQkPwVCgAASiSnw47NZtOIESM0YsQI+43C3t7eBV5YYGCgpKtnb4KCguztSUlJ9rM9gYGBunjxok6dOuVwdicpKUnh4eG5btvDw0MeHh4FXjMAACh58vUhUG9v70IJOpJUs2ZNBQYGOjzOfvHiRa1du9YeZFq0aCE3NzeHPseOHdOuXbuuG3YAAMBfx02d2WnevPkNLx1l2bZt203vPC0tTb/99pt9Pj4+Xjt27JCvr6+qV6+u4cOHa/z48apTp47q1Kmj8ePHq1y5cnrooYckST4+Pho0aJBeeOEF+fn5ydfXV6NGjVLjxo3tT2cBAIC/tpsKO/fdd1+h7HzLli3q0KGDfT7rPpoBAwZozpw5+vvf/67z58/rueee06lTp9SmTRutWLHC4WzSO++8I1dXV/Xr10/nz59Xp06dNGfOHLm4uBRKzQAAoHS5qbAzduzYQtl5RESEjDG5LrfZbIqOjlZ0dHSufTw9PTVt2jRNmzatECoEAAClXZ6+jSVdPSvz529jtWjRoiDrAgAAKBBOh50jR47owQcf1HfffaeKFStKkk6fPq3w8HB99tlnPMINAABKFKefxnriiSd06dIl7d27VydPntTJkye1d+9eGWM0aNCgwqgRAAAgz5w+s7N+/Xpt3LhR9erVs7fVq1dP06ZNU7t27Qq0OAAAgPxy+sxO9erVdenSpWztly9fVtWqVQukKAAAgILidNiZNGmShgwZoi1bttifpNqyZYuGDRumt99+u8ALBAAAyA+nL2MNHDhQ6enpatOmjVxdr65++fJlubq66oknntATTzxh73vy5MmCqxQAACAPnA47U6dOLYQyAAAACofTYWfAgAGFUQcAAEChyPNLBZOSkpSUlKTMzEyH9iZNmuS7KAAAgILidNjZunWrBgwYYH+3zp/ZbDZduXKlwIoDAADIL6fDzuOPP666detq5syZCggIuOmvoQMAABQHp8NOfHy8Fi1apFtuuaUw6gEAAChQTr9np1OnTtq5c2dh1AIAAFDgnD6z88knn2jAgAHatWuXwsLC5Obm5rD8nnvuKbDiAAAA8svpsLNx40Zt2LBB//3vf7Mt4wZlAABQ0jh9GWvo0KF69NFHdezYMWVmZjpMBB0AAFDSOB12UlJSNGLECAUEBBRGPQAAAAXK6bDTu3dvrV69ujBqAQAAKHBO37NTt25dRUVFacOGDWrcuHG2G5SHDh1aYMUBAADkV56exipfvrzWrl2rtWvXOiyz2WyEHQAAUKLk6aWCAAAApYXT9+xkuXjxovbt26fLly8XZD0AAAAFyumwk56erkGDBqlcuXJq1KiREhISJF29V2fixIkFXiAAAEB+OB12oqKitHPnTq1Zs0aenp729s6dOysmJqZAiwMAAMgvp+/ZWbJkiWJiYtS2bVuHL543bNhQBw4cKNDiAAAA8svpMzsnTpxQlSpVsrWfO3fOIfwAAACUBE6HnVatWik2NtY+nxVwPv74Y912220FVxkAAEABcPoy1oQJE9StWzft2bNHly9f1rvvvqvdu3dr06ZN2d67AwAAUNycPrMTHh6u7777Tunp6apdu7ZWrFihgIAAbdq0SS1atCiMGgEAAPLM6TM7ktS4cWPNnTu3oGsBAAAocHl+qSAAAEBpQNgBAACWRtgBAACWRtgBAACWRtgBAACW5vTTWBcuXNC0adO0evVqJSUlKTMz02H5tm3bCqw4AACA/HI67DzxxBOKi4tT37591bp1az4RAQAASjSnw05sbKyWLl2qdu3aFUY9AAAABcrpe3aqVq0qb2/vwqglRzVq1JDNZss2Pf/885KkgQMHZlvWtm3bIqsPAACUbE6HncmTJ+ull17SoUOHCqOebDZv3qxjx47Zp7i4OEnS/fffb+/TrVs3hz5Lly4tktoAAEDJ5/RlrJYtW+rChQuqVauWypUrJzc3N4flJ0+eLLDiJKly5coO8xMnTlTt2rXVvn17e5uHh4cCAwMLdL8AAMAanA47Dz74oP744w+NHz9eAQEBRXqD8sWLFzVv3jyNHDnSYb9r1qxRlSpVVLFiRbVv315vvPGGqlSpkut2MjIylJGRYZ9PTU0t1LoBAEDxcTrsbNy4UZs2bVLTpk0Lo57rWrJkiU6fPq2BAwfa2yIjI3X//fcrNDRU8fHxevXVV9WxY0dt3bpVHh4eOW5nwoQJGjduXBFVDQAAipPTYad+/fo6f/58YdRyQzNnzlRkZKSCg4Ptbf3797f/OSwsTC1btlRoaKhiY2PVu3fvHLcTFRWlkSNH2udTU1MVEhJSeIUDAIBi43TYmThxol544QW98cYbaty4cbZ7dipUqFBgxf3ZoUOHtHLlSi1atOi6/YKCghQaGqr9+/fn2sfDwyPXsz4AAMBanA473bp1kyR16tTJod0YI5vNpitXrhRMZdeYPXu2qlSpou7du1+3X0pKig4fPqygoKBCqQMAAJQuToed1atXF0Yd15WZmanZs2drwIABcnX9X8lpaWmKjo5Wnz59FBQUpIMHD+rll1+Wv7+/evXqVeR1AgCAksfpsPPnR76LysqVK5WQkKAnnnjCod3FxUU///yzPv30U50+fVpBQUHq0KGDYmJiivTFhwAAoORyOuysW7fuusvvvPPOPBeTmy5dusgYk629bNmyWr58eYHvDwAAWIfTYSciIiJb25/feVNY9+wAAADkhdOfizh16pTDlJSUpGXLlqlVq1ZasWJFYdQIAACQZ06f2fHx8cnWdtddd8nDw0MjRozQ1q1bC6QwAACAguD0mZ3cVK5cWfv27SuozQEAABQIp8/s/PTTTw7zxhgdO3ZMEydOLJZPSAAAAFyP02GnWbNmstls2Z6Oatu2rWbNmlVghQEAABQEp8NOfHy8w3yZMmVUuXJleXp6FlhRAAAABcXpsBMaGloYdQAAABQKp8OOJK1atUqrVq1SUlKSMjMzHZZxKQsAAJQkToedcePG6bXXXlPLli0VFBTk8EJBAACAksbpsPPhhx9qzpw5evTRRwujHgAAgALl9Ht2Ll68qPDw8MKoBQAAoMA5HXaefPJJLViwoDBqAQAAKHBOX8a6cOGC/vWvf2nlypVq0qSJ3NzcHJZPmTKlwIoDAADIrzy9QblZs2aSpF27djks42ZlAABQ0jgddlavXl0YdQAAABSKAvsQKAAAQElE2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZWosNOdHS0bDabwxQYGGhfboxRdHS0goODVbZsWUVERGj37t3FWDEAAChpSnTYkaRGjRrp2LFj9unnn3+2L5s0aZKmTJmi6dOna/PmzQoMDNRdd92ls2fPFmPFAACgJCnxYcfV1VWBgYH2qXLlypKuntWZOnWqXnnlFfXu3VthYWGaO3eu0tPTtWDBgmKuGgAAlBQlPuzs379fwcHBqlmzph544AH9/vvvkqT4+HglJiaqS5cu9r4eHh5q3769Nm7ceN1tZmRkKDU11WECAADWVKLDTps2bfTpp59q+fLl+vjjj5WYmKjw8HClpKQoMTFRkhQQEOCwTkBAgH1ZbiZMmCAfHx/7FBISUmjHAAAAileJDjuRkZHq06ePGjdurM6dOys2NlaSNHfuXHsfm83msI4xJlvbtaKionTmzBn7dPjw4YIvHgAAlAglOuxcy8vLS40bN9b+/fvtT2VdexYnKSkp29mea3l4eKhChQoOEwAAsKZSFXYyMjK0d+9eBQUFqWbNmgoMDFRcXJx9+cWLF7V27VqFh4cXY5UAAKAkcS3uAq5n1KhR6tmzp6pXr66kpCS9/vrrSk1N1YABA2Sz2TR8+HCNHz9ederUUZ06dTR+/HiVK1dODz30UHGXDgAASogSHXaOHDmiBx98UMnJyapcubLatm2r77//XqGhoZKkv//97zp//ryee+45nTp1Sm3atNGKFSvk7e1dzJUDAICSokSHnc8///y6y202m6KjoxUdHV00BQEAgFKnVN2zAwAA4CzCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTX4i4AJdfevXuLuwSn+Pv7q3r16sVdBgCghCHsIJsraackm02PPPJIcZfiFM+y5bTvl70EHgCAA8IOssnMSJOMkV+PF+TmF1Lc5dyUSymHlfLNZCUnJxN2AAAOCDvIlZtfiDwCbynuMgAAyBduUAYAAJZG2AEAAJZG2AEAAJZG2AEAAJZWosPOhAkT1KpVK3l7e6tKlSq67777tG/fPoc+AwcOlM1mc5jatm1bTBUDAICSpkSHnbVr1+r555/X999/r7i4OF2+fFldunTRuXPnHPp169ZNx44ds09Lly4tpooBAEBJU6IfPV+2bJnD/OzZs1WlShVt3bpVd955p73dw8NDgYGBN73djIwMZWRk2OdTU1PzXywAACiRSvSZnWudOXNGkuTr6+vQvmbNGlWpUkV169bVU089paSkpOtuZ8KECfLx8bFPISGl48V5AADAeaUm7BhjNHLkSN1+++0KCwuzt0dGRmr+/Pn69ttvNXnyZG3evFkdO3Z0OHNzraioKJ05c8Y+HT58uCgOAQAAFIMSfRnrz/72t7/pp59+0oYNGxza+/fvb/9zWFiYWrZsqdDQUMXGxqp37945bsvDw0MeHh6FWi8AACgZSkXYGTJkiL7++mutW7dO1apVu27foKAghYaGav/+/UVUHQAAKMlKdNgxxmjIkCFavHix1qxZo5o1a95wnZSUFB0+fFhBQUFFUCEAACjpSvQ9O88//7zmzZunBQsWyNvbW4mJiUpMTNT58+clSWlpaRo1apQ2bdqkgwcPas2aNerZs6f8/f3Vq1evYq4eAACUBCX6zM4HH3wgSYqIiHBonz17tgYOHCgXFxf9/PPP+vTTT3X69GkFBQWpQ4cOiomJkbe3dzFUDAAASpoSHXaMMdddXrZsWS1fvryIqgEgSQkJCUpOTi7uMpzi7++v6tWrF3cZAIpJiQ47AEqWhIQE1avfQBfOpxd3KU7xLFtO+37ZS+AB/qIIOwBuWnJysi6cT5dfjxfk5lc6XsZ5KeWwUr6ZrOTkZMIO8BdF2AHgNDe/EHkE3lLcZQDATSnRT2MBAADkF2EHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYmmtxFwAAQHFJSEhQcnJycZdx0/bu3VvcJZRKhB0AwF9SQkKC6tVvoAvn04u7FBQywg4spbT9q8ff31/Vq1cv7jKAv6Tk5GRdOJ8uvx4vyM0vpLjLuSnnf9+iM+vnFXcZpQ5hB5ZwJe2UZLPpkUceKe5SnOJZtpz2/bKXwAMUIze/EHkE3lLcZdyUSymHi7uEUomwA0vIzEiTjClV/0K7lHJYKd9MVnJyMmEHAAoRYQeWUpr+hQYAKBo8eg4AACyNsAMAACyNy1gAUAKVtve/SDxdiJKLsAMAJUxpff8LTxeipCLsAMWsNL0bqDTVWpqVxve/ZD1duH79ejVo0KC4y7kp/Dz/dRB2gGJSWt8NhKJTmp4u5OcZJRlhBygmpfHdQLy9Fbnh5xklGWEHKGal6V/vvL0VN8LPM0oiwg6Av4TSdH9GaaoVKA0IOwAsjXtJABB2AFga95IAIOwA+EvgXhLgr4vPRQAAAEsj7AAAAEsj7AAAAEuzTNiZMWOGatasKU9PT7Vo0ULr168v7pIAAEAJYImwExMTo+HDh+uVV17R9u3bdccddygyMlIJCQnFXRoAAChmlgg7U6ZM0aBBg/Tkk0+qQYMGmjp1qkJCQvTBBx8Ud2kAAKCYlfpHzy9evKitW7dq9OjRDu1dunTRxo0bc1wnIyNDGRkZ9vkzZ85IklJTUwu0trS0tKv7S/xNmRcvFOi2C1PWY6+lqW5qLhrUXDSouWhQc9G4dPKIpKu/Ewv692zW9owx1+9oSrk//vjDSDLfffedQ/sbb7xh6tatm+M6Y8eONZKYmJiYmJiYLDAdPnz4ulmh1J/ZyWKz2RzmjTHZ2rJERUVp5MiR9vnMzEydPHlSfn5+ua6TV6mpqQoJCdHhw4dVoUKFAt32XxnjWjgY18LBuBYOxrVwlKZxNcbo7NmzCg4Ovm6/Uh92/P395eLiosTERIf2pKQkBQQE5LiOh4eHPDw8HNoqVqxYWCVKkipUqFDif2hKI8a1cDCuhYNxLRyMa+EoLePq4+Nzwz6l/gZld3d3tWjRQnFxcQ7tcXFxCg8PL6aqAABASVHqz+xI0siRI/Xoo4+qZcuWuu222/Svf/1LCQkJeuaZZ4q7NAAAUMwsEXb69++vlJQUvfbaazp27JjCwsK0dOlShYaGFndp8vDw0NixY7NdNkP+MK6Fg3EtHIxr4WBcC4cVx9VmzI2e1wIAACi9Sv09OwAAANdD2AEAAJZG2AEAAJZG2AEAAJZG2CkAM2bMUM2aNeXp6akWLVpo/fr11+2/du1atWjRQp6enqpVq5Y+/PDDIqq0dHFmXBctWqS77rpLlStXVoUKFXTbbbdp+fLlRVht6eHsz2uW7777Tq6urmrWrFnhFlhKOTuuGRkZeuWVVxQaGioPDw/Vrl1bs2bNKqJqSw9nx3X+/Plq2rSpypUrp6CgID3++ONKSUkpompLh3Xr1qlnz54KDg6WzWbTkiVLbrhOqf+9VSAfqPoL+/zzz42bm5v5+OOPzZ49e8ywYcOMl5eXOXToUI79f//9d1OuXDkzbNgws2fPHvPxxx8bNzc38+WXXxZx5SWbs+M6bNgw8+abb5off/zR/PrrryYqKsq4ubmZbdu2FXHlJZuz45rl9OnTplatWqZLly6madOmRVNsKZKXcb3nnntMmzZtTFxcnImPjzc//PBDtm/8/dU5O67r1683ZcqUMe+++675/fffzfr1602jRo3MfffdV8SVl2xLly41r7zyilm4cKGRZBYvXnzd/lb4vUXYyafWrVubZ555xqGtfv36ZvTo0Tn2//vf/27q16/v0DZ48GDTtm3bQquxNHJ2XHPSsGFDM27cuIIurVTL67j279/fjBkzxowdO5awkwNnx/W///2v8fHxMSkpKUVRXqnl7Li+9dZbplatWg5t7733nqlWrVqh1Vja3UzYscLvLS5j5cPFixe1detWdenSxaG9S5cu2rhxY47rbNq0KVv/rl27asuWLbp06VKh1Vqa5GVcr5WZmamzZ8/K19e3MEoslfI6rrNnz9aBAwc0duzYwi6xVMrLuH799ddq2bKlJk2apKpVq6pu3boaNWqUzp8/XxQllwp5Gdfw8HAdOXJES5culTFGx48f15dffqnu3bsXRcmWZYXfW5Z4g3JxSU5O1pUrV7J9cDQgICDbh0mzJCYm5tj/8uXLSk5OVlBQUKHVW1rkZVyvNXnyZJ07d079+vUrjBJLpbyM6/79+zV69GitX79erq787yIneRnX33//XRs2bJCnp6cWL16s5ORkPffcczp58iT37fx/eRnX8PBwzZ8/X/3799eFCxd0+fJl3XPPPZo2bVpRlGxZVvi9xZmdAmCz2RzmjTHZ2m7UP6f2vzpnxzXLZ599pujoaMXExKhKlSqFVV6pdbPjeuXKFT300EMaN26c6tatW1TllVrO/LxmZmbKZrNp/vz5at26te6++25NmTJFc+bM4ezONZwZ1z179mjo0KH6xz/+oa1bt2rZsmWKj4/nO4kFoLT/3uKfavng7+8vFxeXbP/KSEpKypaCswQGBubY39XVVX5+foVWa2mSl3HNEhMTo0GDBumLL75Q586dC7PMUsfZcT179qy2bNmi7du3629/+5ukq7+kjTFydXXVihUr1LFjxyKpvSTLy89rUFCQqlatKh8fH3tbgwYNZIzRkSNHVKdOnUKtuTTIy7hOmDBB7dq104svvihJatKkiby8vHTHHXfo9ddfLxVnIEoiK/ze4sxOPri7u6tFixaKi4tzaI+Li1N4eHiO69x2223Z+q9YsUItW7aUm5tbodVamuRlXKWrZ3QGDhyoBQsWcI0+B86Oa4UKFfTzzz9rx44d9umZZ55RvXr1tGPHDrVp06aoSi/R8vLz2q5dOx09elRpaWn2tl9//VVlypRRtWrVCrXe0iIv45qenq4yZRx/rbm4uEj635kIOM8Sv7eK6cZoy8h6NHLmzJlmz549Zvjw4cbLy8scPHjQGGPM6NGjzaOPPmrvn/UI34gRI8yePXvMzJkzS90jfEXB2XFdsGCBcXV1Ne+//745duyYfTp9+nRxHUKJ5Oy4XounsXLm7LiePXvWVKtWzfTt29fs3r3brF271tSpU8c8+eSTxXUIJZKz4zp79mzj6upqZsyYYQ4cOGA2bNhgWrZsaVq3bl1ch1AinT171mzfvt1s377dSDJTpkwx27dvtz/Sb8XfW4SdAvD++++b0NBQ4+7ubm699Vazdu1a+7IBAwaY9u3bO/Rfs2aNad68uXF3dzc1atQwH3zwQRFXXDo4M67t27c3krJNAwYMKPrCSzhnf17/jLCTO2fHde/evaZz586mbNmyplq1ambkyJEmPT29iKsu+Zwd1/fee880bNjQlC1b1gQFBZmHH37YHDlypIirLtlWr1593f9fWvH3ls0Yzu0BAADr4p4dAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdACWOMUZPP/20fH19ZbPZtGPHjhz7LVmyRLfccotcXFw0fPjwm9r2wIEDdd9999nnIyIibnrdP4uOjlazZs2cXg9A0SPsALhp8+fPV0hIiHx9fe1fls5y8OBB1a1bV6mpqfnez7JlyzRnzhx98803OnbsmMLCwnLsN3jwYPXt21eHDx/WP//5z3zvNzc2m01LlixxaBs1apRWrVpVaPsEUHBci7sAAKVDcnKynnzySc2ZM0e1atVS9+7dFRERYf/C/LPPPquJEyeqQoUK+d7XgQMHFBQUdN2v3KelpSkpKUldu3ZVcHBwvvfprPLly6t8+fJFvl8AzuPMDoCb8vvvv8vHx0f9+/dXq1at1KFDB+3Zs0eStGDBArm7u6t37943ta21a9eqdevW8vDwUFBQkEaPHq3Lly9LunqZaciQIUpISJDNZlONGjWyrb9mzRp5e3tLkjp27CibzaY1a9bkeGlp6tSpOW7jZmWt26tXL4d6rt1X1uWx8ePHKyAgQBUrVtS4ceN0+fJlvfjii/L19VW1atU0a9Ysh+3/8ccf6t+/vypVqiQ/Pz/de++9OnjwYJ7rBZAdYQfATalTp47S09O1fft2nTx5Ups3b1aTJk108uRJ/eMf/9D06dNvajt//PGH7r77brVq1Uo7d+7UBx98oJkzZ+r111+XJL377rt67bXXVK1aNR07dkybN2/Oto3w8HDt27dPkrRw4UIdO3bsumeB8iNr/7Nnz861nizffvutjh49qnXr1mnKlCmKjo5Wjx49VKlSJf3www965pln9Mwzz+jw4cOSpPT0dHXo0EHly5fXunXrtGHDBpUvX17dunXTxYsXC+V4gL8iwg6Am1KpUiXNnTtXjz32mFq3bq3HHntMXbt21ahRozRkyBDFx8erefPmCgsL05dffpnrdmbMmKGQkBBNnz5d9evX13333adx48Zp8uTJyszMlI+Pj7y9veXi4qLAwEBVrlw52zbc3d1VpUoVSZKvr68CAwPl7u5eKMedtf+KFSvmWk8WX19fvffee6pXr56eeOIJ1atXT+np6Xr55ZdVp04dRUVFyd3dXd99950k6fPPP1eZMmX0ySefqHHjxmrQoIFmz56thIQErVmzplCOB/gr4p4dADetV69e6tWrl31+zZo1+vnnnzV9+nTdcsst+uyzzxQYGKjWrVvrzjvvtAeSP9u7d69uu+022Ww2e1u7du2UlpamI0eOqHr16kVyLDkZP368xo8fb5/fs2ePU/U0atRIZcr879+QAQEBDjdXu7i4yM/PT0lJSZKkrVu36rfffrNfksty4cIFHThwIK+HAeAahB0AeZKRkaHnnntO8+bN02+//abLly+rffv2kqS6devqhx9+UM+ePbOtZ4xxCDpZbZKytTurTJky9m1luXTp0k2v/8wzz6hfv372eWdvfHZzc3OYt9lsObZlZmZKkjIzM9WiRQvNnz8/27audwYJgHMIOwDy5J///KciIyN16623avv27fYbjKWrAePKlSs5rtewYUMtXLjQIfRs3LhR3t7eqlq1ar5qqly5shITEx22nds7enLi6+srX1/fbO1ubm65Hk9+3HrrrYqJiVGVKlUK5Ck2ADnjnh0ATtu9e7diYmL02muvSZLq16+vMmXKaObMmYqNjdUvv/yiVq1a5bjuc889p8OHD2vIkCH65Zdf9NVXX2ns2LEaOXKkwyWgvIiIiNCJEyc0adIkHThwQO+//77++9//5mub0tUnslatWqXExESdOnUq39vL8vDDD8vf31/33nuv1q9fr/j4eK1du1bDhg3TkSNHCmw/wF8dYQeAU7LebvzOO+/Iy8tLklS2bFnNmTNHr732mgYNGqTp06fnepamatWqWrp0qX788Uc1bdpUzzzzjAYNGqQxY8bku7YGDRpoxowZev/999W0aVP9+OOPGjVqVL63O3nyZMXFxSkkJETNmzfP9/aylCtXTuvWrVP16tXVu3dvNWjQQE888YTOnz/PmR6gANnMtRe4AQAALIQzOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNL+H5BPRGUS8XIOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the histogram\n",
    "plt.hist(df['FTE'].dropna(), ec='k')  # .dropna() isn't needed\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of %full-time \\n employee works')\n",
    "plt.xlabel('% of full-time')\n",
    "plt.ylabel('num employees')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae073d7-a2cf-4215-a253-efaad52c4cac",
   "metadata": {},
   "source": [
    "**The high variance in expenditures makes sense (some purchases are cheap some are expensive). Also, it looks like the FTE column is bimodal. That is, there are some part-time and some full-time employees.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a4152c6-4d74-44dc-8764-34b7703bffd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     23\n",
       "float64     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a4285-a60d-439e-a0bb-4d4e7cbdd00c",
   "metadata": {},
   "source": [
    "## Encode the Labels as Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bed5b8b-46e5-4c58-8178-d0df14ba9d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Use                 category\n",
      "Sharing             category\n",
      "Reporting           category\n",
      "Student_Type        category\n",
      "Position_Type       category\n",
      "Object_Type         category\n",
      "Pre_K               category\n",
      "Operating_Status    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "LABELS_td = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status']\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "df[LABELS_td] = df[LABELS_td].apply(categorize_label)\n",
    "print(df[LABELS_td].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f438ff-2132-487b-a4fc-47d2fc318245",
   "metadata": {},
   "source": [
    "## Counting Unique Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa046f05-270d-4ba9-8d7e-bbcf6c4edfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_unique_labels = df[LABELS_td].apply(pd.Series.nunique)\n",
    "ax = num_unique_labels.plot(kind='bar', ylabel='Number of Unique Categories', xlabel='Column Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa6ec4b-6f90-4a2c-820e-0adaeca72b2f",
   "metadata": {},
   "source": [
    "## `def compute_log_loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fe98be5-ce50-4caf-a513-1d2898cd8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_loss(predicted: Union[float, List[float]], actual: [int, List[int]], eps: float=1e-14) -> float:\n",
    "    \"\"\"\n",
    "    Computes the logarithmic loss between predicted and \n",
    "    actual when these are 1D arrays\n",
    "\n",
    "    :param predicted: The predicted probabilities as floats between 0-1\n",
    "    :param actual: The actual binary labels. Either 0 or 1\n",
    "    :param eps (optional): log(0) is inf, so we need to offset our\n",
    "                           precidted values slightly by eps from 0 to 1.\n",
    "    \"\"\"\n",
    "\n",
    "    predicted = np.clip(predicted, eps, 1 - eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted)\n",
    "                        + (1 - actual)\n",
    "                        * np.log(1 - predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23552926-321e-4bf9-9669-7068bc1e60b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16251892949777494\n",
      "4.605170185988091\n",
      "0.7133498878774648\n"
     ]
    }
   ],
   "source": [
    "data = [(0.85, 1), (0.99, 0), (0.51, 0)]\n",
    "\n",
    "for p, y in data:\n",
    "    print(compute_log_loss(p, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd275576-9af3-40e1-9d3a-f97860f3a316",
   "metadata": {},
   "source": [
    "**Lowest: A, Middle: C, Highest: B**\n",
    "\n",
    "**Of the two incorrect predictions, B will have a higher log loss because it is confident and wrong.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deea260-0aea-4c79-ba4e-b4815d7559fa",
   "metadata": {},
   "source": [
    "## Computing log loss with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e9931b-c32a-43e9-b7c2-53fd2010b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_confident = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.05, 0.05, 0.05, 0.05, 0.05])\n",
    "correct_not_confident = np.array([0.65, 0.65, 0.65, 0.65, 0.65, 0.35, 0.35, 0.35, 0.35, 0.35])\n",
    "wrong_not_confident = np.array([0.35, 0.35, 0.35, 0.35, 0.35, 0.65, 0.65, 0.65, 0.65, 0.65])\n",
    "wrong_confident = np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.95, 0.95, 0.95, 0.95, 0.95])\n",
    "actual_labels = np.array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2cbe99d-ee7b-4b22-823a-5fb204bba355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss, correct and confident: 0.05129329438755058\n",
      "Log loss, correct and not confident: 0.4307829160924542\n",
      "Log loss, wrong and not confident: 1.049822124498678\n",
      "Log loss, wrong and confident: 2.9957322735539904\n",
      "Log loss, actual labels: 9.99200722162646e-15\n"
     ]
    }
   ],
   "source": [
    "# Compute and print log loss for 1st case\n",
    "correct_confident_loss = compute_log_loss(correct_confident, actual_labels)\n",
    "print(\"Log loss, correct and confident: {}\".format(correct_confident_loss)) \n",
    "\n",
    "# Compute log loss for 2nd case\n",
    "correct_not_confident_loss = compute_log_loss(correct_not_confident, actual_labels)\n",
    "print(\"Log loss, correct and not confident: {}\".format(correct_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 3rd case\n",
    "wrong_not_confident_loss = compute_log_loss(wrong_not_confident, actual_labels)\n",
    "print(\"Log loss, wrong and not confident: {}\".format(wrong_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 4th case\n",
    "wrong_confident_loss = compute_log_loss(wrong_confident, actual_labels)\n",
    "print(\"Log loss, wrong and confident: {}\".format(wrong_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for actual labels\n",
    "actual_labels_loss = compute_log_loss(actual_labels, actual_labels)\n",
    "print(\"Log loss, actual labels: {}\".format(actual_labels_loss)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71d5d17-738b-4d7a-837c-5349702dc891",
   "metadata": {},
   "source": [
    "**Log loss penalizes highly confident wrong answers much more than any other type. This will be a good metric to use on your models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3842af-d395-4ab3-8d59-1ba934a936ef",
   "metadata": {},
   "source": [
    "# Creating a simple first model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e356e-6dd2-49e2-9a4a-decbd15701d5",
   "metadata": {},
   "source": [
    "## It's time to build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a257a0-cfb6-4acb-b6f6-a5555a644d61",
   "metadata": {},
   "source": [
    "```python\n",
    "data_to_train = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "labels_to_use = pd.get_dummies(df[LABELS])\n",
    "\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(data_to_train, labels_to_use, size=0.2, seed=123)\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "clf.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cdde3a-ed94-48f6-935e-718d56ecd376",
   "metadata": {},
   "source": [
    "### Setting up a train-test split in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe20bd07-e061-42df-9d1b-b9828dcd499f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1040 entries, 198 to 101861\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   FTE     1040 non-null   float64\n",
      " 1   Total   1040 non-null   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 24.4 KB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 520 entries, 209 to 448628\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   FTE     520 non-null    float64\n",
      " 1   Total   520 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 12.2 KB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1040 entries, 198 to 101861\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: bool(104)\n",
      "memory usage: 113.8 KB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 520 entries, 209 to 448628\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: bool(104)\n",
      "memory usage: 56.9 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\users\\trenton\\Dropbox\\PythonProjects\\DataCamp\\functions\\multilabel.py:31: UserWarning: Size less than number of columns * min_count, returning 520 items instead of 312.0.\n",
      "  warn(msg.format(y.shape[1] * min_count, size))\n"
     ]
    }
   ],
   "source": [
    "NUMERIC_COLUMNS_td = df.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Create the new DataFrame: numeric_data_only\n",
    "numeric_data_only = df[NUMERIC_COLUMNS_td].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS_td])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c77394-64ca-4471-90a8-73cd2bd38f14",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41707c4f-006f-48fc-9847-1f6cd6789a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da410827-3364-45df-94ed-125da1a6750c",
   "metadata": {},
   "source": [
    "**The good news is that your workflow didn't cause any errors. The bad news is that your model scored the lowest possible accuracy: 0.0! But hey, you just threw away ALL of the text data in the budget. Later, you won't. Before you add the text data, let's see how the model does when scored by log loss.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae519164-080b-4993-a82e-80a218b78500",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc45dec5-f913-47f5-94aa-1a8b1fbcdcda",
   "metadata": {},
   "source": [
    "```python\n",
    "houldout = pd.read_csv('HoldoutData.csv', index_col=0)\n",
    "holdout = holdout[NUMERIC_COLUMNS].fillna(-1000)\n",
    "predictions = clf.predict_proba(holdout)\n",
    "```\n",
    "\n",
    "- Using `.predict()`\n",
    "  - would result in an output of 0 or 1\n",
    "  - Log loss penalized being confident and wrong\n",
    "  - Worse performance compared to `.predict_proba()`\n",
    "\n",
    "- Format and submit predictions\n",
    "```python\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS], prefix_sep='__').columns, index=houldout.index, data=predictions)\n",
    "prediction_df.to_csv('predictions.csv')\n",
    "score = score_submission(pred_path='predictions.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a60c0-2f7f-479e-81de-a7dffaf8515b",
   "metadata": {},
   "source": [
    "### Use your model to predict values on holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c1f53fd-8846-4a21-9605-90ca91ca08f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit it to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Load the holdout data: holdout\n",
    "holdout = pd.read_csv('data/2024-01-19_school_budgeting_with_machine_learning_in_python/HoldoutData.csv', index_col=0)\n",
    "\n",
    "# Generate predictions: predictions\n",
    "NUMERIC_COLUMNS_hd = holdout.select_dtypes(include='number').columns\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS_hd].fillna(-1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f6251-2ebf-403c-9e64-6192cf7ea705",
   "metadata": {},
   "source": [
    "### Writing out your results to a csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a69f822a-ed43-4139-ada1-390c9fab0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format predictions in DataFrame: prediction_df\n",
    "# pd.get_dummies(df[LABELS], ...) is correctly using df, not holdout\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS_td], prefix_sep='__').columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('data/2024-01-19_school_budgeting_with_machine_learning_in_python/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea2ce94e-6704-40d2-a91f-5676f30a6d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model, trained with numeric data only, yields logloss score: 1.9922002736361633\n"
     ]
    }
   ],
   "source": [
    "# requires functions and variables from https://goodboychan.github.io/python/datacamp/machine_learning/2020/06/05/01-School-Budgeting-with-Machine-Learning-in-Python.html\n",
    "# BOX_PLOTS_COLUMN_INDICES, def _multi_multi_log_loss, and def score_submissio\n",
    "\n",
    "# Submit the predictions for scoring: score\n",
    "score = score_submission(pred_path='data/2024-01-19_school_budgeting_with_machine_learning_in_python/predictions.csv', holdout_path='data/2024-01-19_school_budgeting_with_machine_learning_in_python/TestSetLabelsSample.csv')\n",
    "\n",
    "# Print score\n",
    "print('Your model, trained with numeric data only, yields logloss score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68f7382-5f4b-4f01-a69a-dda406e6b18d",
   "metadata": {},
   "source": [
    "**Even though your basic model scored 0.0 accuracy, it nevertheless performs better than the benchmark score of 2.0455. You've now got the basics down and have made a first pass at this complicated supervised learning problem. It's time to step up your game and incorporate the text data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a52a4e-4b36-4977-81a0-74ebae25a8af",
   "metadata": {},
   "source": [
    "## A very brief introduction to NLP\n",
    "\n",
    "- Data for NLP:\n",
    "  - Text, documents, speech, ...\n",
    "- Tokenization\n",
    "  - Splitting a string into segments\n",
    "  - Store segments as list\n",
    "- Example: \"Natural Language Processing\"\n",
    "  - ['Natural', 'Language', 'Processing']\n",
    "\n",
    "- Tokenize on whitespace\n",
    "  - Petro-vend fuel and fluids\n",
    "    - Petro-vend | fuel | and | fluids\n",
    "- Tokenize on whitespace and punctuation\n",
    "  - Petro | vend | fuel | and | fluids\n",
    " \n",
    "- Bag of words representation\n",
    "  - Count the umber of times a particular token appears\n",
    "  - 'Bag of words'\n",
    "    - Count the number of times a word was pulled out of the bag\n",
    "- The approach discards information about word order\n",
    "  - 'Red, not blue' is the same as 'blue, not red'\n",
    " \n",
    "- 1-gram, 2-gram, ..., n-gram\n",
    "  - ![][1]\n",
    " \n",
    "[1]: https://raw.githubusercontent.com/trenton3983/DataCamp/master/Images/2024-01-19_school_budgeting_with_machine_learning_in_python/sb01.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1dbd9-e30e-4219-9dac-cc6f47deb127",
   "metadata": {},
   "source": [
    "## A very brief introduction to NLP\n",
    "\n",
    "- Data for NLP:\n",
    "  - Text, documents, speech, ...\n",
    "- Tokenization\n",
    "  - Splitting a string into segments\n",
    "  - Store segments as list\n",
    "- Example: \"Natural Language Processing\"\n",
    "  - ['Natural', 'Language', 'Processing']\n",
    "\n",
    "- Tokenize on whitespace\n",
    "  - Petro-vend fuel and fluids\n",
    "    - Petro-vend | fuel | and | fluids\n",
    "- Tokenize on whitespace and punctuation\n",
    "  - Petro | vend | fuel | and | fluids\n",
    " \n",
    "- Bag of words representation\n",
    "  - Count the umber of times a particular token appears\n",
    "  - 'Bag of words'\n",
    "    - Count the number of times a word was pulled out of the bag\n",
    "- The approach discards information about word order\n",
    "  - 'Red, not blue' is the same as 'blue, not red'\n",
    " \n",
    "- 1-gram, 2-gram, ..., n-gram\n",
    "  - ![][1]\n",
    " \n",
    "[1]: https://raw.githubusercontent.com/trenton3983/DataCamp/master/Images/2024-01-19_school_budgeting_with_machine_learning_in_python/sb01.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26493578-8b50-4d8b-b5d9-70cf54c38f8e",
   "metadata": {},
   "source": [
    "### Tokenizating text\n",
    "\n",
    "- 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7658c31c-bb85-4322-b400-cb3d19c6fedf",
   "metadata": {},
   "source": [
    "### Testing your NLP credentials with n-grams\n",
    "\n",
    "- 12 - The number of `1-grams + 2-grams + 3-grams` is `5 + 4 + 3 = 12`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda3cb6-c027-42da-815b-de5c1b5bfe8a",
   "metadata": {},
   "source": [
    "## Representing text numerically\n",
    "\n",
    "**Scikit-learn tools for bag-of-words**\n",
    "\n",
    "- `CountVectorizer()`\n",
    "  - Tokenizes all the strings\n",
    "  - Builds a 'vocabulary'\n",
    "  - Counts the occurrences of each token in the vocabulary\n",
    " \n",
    "**Using `CountVectorizer() on a column of main dataset**\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import CountVecotrizer\n",
    "\n",
    "TOKENS_BASIC = '\\\\\\\\S+(?=\\\\\\\\s+)'\n",
    "df.Program_Description.fillna('', inplace=True)\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "vec_basic.fit(df.Program_Description)\n",
    "msg = 'There are {} token in Program_Desction if tokean are any non-whitespace'\n",
    "print(msg.format(len(vec_basic.get_feature_names())))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c900a0-2c4e-4aab-b89c-f6ab32b49a50",
   "metadata": {},
   "source": [
    "### Creating a bag-of-words in scikit-learn\r\n",
    "\r\n",
    "In this exercise, you'll study the effects of tokenizing in different ways by comparing the bag-of-words representations resulting from different token patterns.\r\n",
    "\r\n",
    "You will focus on one feature only, the `Position_Extra` column, which describes any additional information not captured by the `Position_Type` label.\r\n",
    "\r\n",
    "For example, in the Shell you can check out the budget item in row 8960 of the data using `df.loc[8960]`. Looking at the output reveals that this `Object_Description` is overtime pay. For who? The Position Type is merely \"other\", but the Position Extra elaborates: \"BUS DRIVER\". Explore the column further to see more instances. It has a lot of NaN values.\r\n",
    "\r\n",
    "Your task is to turn the raw text in this column into a bag-of-words representation by creating tokens that contain only alphanumeric characters.\r\n",
    "\r\n",
    "For comparison purposes, the first 15 tokens of `vec_basic`, which splits `df.Position_Extra` into tokens when it encounters only whitespace characters, have been printed along with the length of the representation.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Import `CountVectorizer` from `sklearn.feature_extraction.text`.\r\n",
    "- Fill missing values in `df.Position_Extra` using `.fillna('')` to replace NaNs with empty strings. Specify the additional keyword argument `inplace=True` so that you don't have to assign the result back to `df`.\r\n",
    "- Instantiate the `CountVectorizer` as `vec_alphanumeric` by specifying the `token_pattern` to be `TOKENS_ALPHANUMERIC`.\r\n",
    "- Fit `vec_alphanumeric` to `df.Position_Extra`.\r\n",
    "- Hit submit to see the `len` of the fitted representation as well as the first 15 elements, and compare to `vec_basic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3529766f-ddf4-4c1a-856a-3e9244c7f769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 123 tokens in Position_Extra if we split on non-alpha numeric\n",
      "['1st' '2nd' '3rd' 'a' 'ab' 'additional' 'adm' 'administrative' 'and'\n",
      " 'any' 'art' 'assessment' 'assistant' 'asst' 'athletic']\n"
     ]
    }
   ],
   "source": [
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "df.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names_out())))\n",
    "print(vec_alphanumeric.get_feature_names_out()[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140f45f-e334-4675-9474-6b649752bc8b",
   "metadata": {},
   "source": [
    "**Treating only alpha-numeric characters as tokens gives you a smaller number of more meaningful tokens.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aba1af-baa2-4e3b-a86b-879b10e9bc68",
   "metadata": {},
   "source": [
    "### Combining text columns for tokenization\r\n",
    "\r\n",
    "In order to get a bag-of-words representation for all the text data in our DataFrame, you must first convert the text data in each row of the DataFrame into a single string.\r\n",
    "\r\n",
    "In the previous exercise, this wasn't necessary because you only looked at one column of data, so each row was already just a single string. `CountVectorizer` expects each row to just be a single string, so in order to use all of the text columns, you'll need a method to turn a list of strings into a single string.\r\n",
    "\r\n",
    "In this exercise, you'll complete the function definition `combine_text_columns()`. When completed, this function will convert all training text data in your DataFrame to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the `.fit_transform()` method.\r\n",
    "\r\n",
    "Note that the function uses `NUMERIC_COLUMNS` and `LABELS` to determine which columns to drop. These lists have been loaded into the workspace.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Use the `.drop()` method on `data_frame` with `to_drop` and `axis=` as arguments to drop the non-text data. Save the result as `text_data`.\r\n",
    "- Fill in missing values (inplace) in `text_data` with blanks (\"\"), using the `.fillna()` method.\r\n",
    "- Complete the `.apply()` method by writing a lambda function that uses the `.join()` method to join all the items in a row with a space in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43ce88b5-901a-4d35-a0d6-28d1fe57f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame: pd.DataFrame, to_drop: list=NUMERIC_COLUMNS_td + LABELS_td) -> pd.Series:\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna('', inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba63d58-a5d9-4334-b33b-571ca73f9851",
   "metadata": {},
   "source": [
    "### What's in a token?\r\n",
    "\r\n",
    "Now you will use `combine_text_columns` to convert all training text data in your DataFrame to a single vector that can be passed to the vectorizer object and made into a bag-of-words using the `.fit_transform()` method.\r\n",
    "\r\n",
    "You'll compare the effect of tokenizing using any non-whitespace characters as a token and using only alphanumeric characters as a token.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Import `CountVectorizer` from `sklearn.feature_extraction.text`.\r\n",
    "- Instantiate `vec_basic` and `vec_alphanumeric` using, respectively, the `TOKENS_BASIC` and `TOKENS_ALPHANUMERIC` patterns.\r\n",
    "- Create the text vector by using the `combine_text_columns()` function on `df`.\r\n",
    "- Using the `.fit_transform()` method with `text_vector`, fit and transform first `vec_basic` and then `vec_alphanumeric`. Print the number of tokens they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab3b92ae-b23b-4b44-89ec-8ce65c364652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1406 tokens in the dataset\n",
      "There are 1118 alpha-numeric tokens in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Create the basic token pattern\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names_out())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names_out())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f1006-ef42-4a30-8ef7-d8c4946b2fda",
   "metadata": {},
   "source": [
    "**Notice that tokenizing on alpha-numeric tokens reduced the number of tokens, just as in the last exercise. We'll keep this in mind when building a better model with the Pipeline object next.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93fbc6-1f47-4655-9e76-b88d2aa82fa3",
   "metadata": {},
   "source": [
    "# Improving your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb87d184-9b25-4124-95c3-2ae39c930d79",
   "metadata": {},
   "source": [
    "## Pipelines, feature & text preprocessing\r\n",
    "\r\n",
    "1. **Pipelines, feature & text preprocessing**: You've submitted your first simple model. Now it's time to combine what we've learned about NLP with our model pipeline and incorporate the text data into our algorithm.\r\n",
    "- Repeatable way to go from raw data to trained model\r\n",
    "- Pipeline object takes sequential list of steps\r\n",
    "  - Output of one step is input to next step\r\n",
    "- Each step is a tuple with two elements\r\n",
    "  - Name: string\r\n",
    "  - Transform: obj implementing .fit() and .transform()\r\n",
    "- Flexible: a step can itself be another pipeline!\r\n",
    "\r\n",
    "2. **The pipeline workflow**: The supervised learning course introduced pipelines, which are a repeatable way to go from raw data to a trained machine learning model. The scikit-learn Pipeline object takes a sequential list of steps where the output of one step is the input to the next. Each step is represented with a name for the step, that is simply a string, and an object that implements the fit and the transform methods. A good example is the `CountVectorizer` that we used earlier. As we'll see Pipelines are a very flexible way to represent your workflow. In fact, you can even have a sub-pipeline as one of the steps! The beauty of the Pipeline is that it encapsulates every transformation from raw data to a trained model.\r\n",
    "\r\n",
    "```python\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.multiclass import OneVsRestClassifier\r\n",
    "pl = Pipeline([('clf', OneVsRestClassifier(LogisticRegression()))])\r\n",
    "```\r\n",
    "\r\n",
    "3. **Instantiate simple pipeline with one step**: After importing the relevant modules, we'll start with a one-step pipeline. Although we don't need a pipeline for a single step, this exercise will get us familiar with the syntax. Remember, we create a Pipeline by passing it a series of named steps. In this case the name is the string 'clf', and the step is the one-vs-rest logistic regression classifier we created earlier.\r\n",
    "\r\n",
    "4. **Train and test with sample numeric data**: The sample dataset we've been working with has numeric data in the numeric columns and the with missing column. We'll start by building a model to predict the label column with the numeric data.\r\n",
    "\r\n",
    "5. **Train and test with sample numeric data**: First, we'll use the train_test split function from sklearn dot model_selection. Our X will just be the numeric column, and our Y will be the dummy encoding of the label column. We'll call the fit method on our Pipeline, just like a normal classifier in sklearn. We can see that it returns a Pipeline that has one step to do our logistic regression.\r\n",
    "\r\n",
    "```python\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric']], pd.get_dummies(sample_df['label']), random_state=2)\r\n",
    "pl.fit(X_train, y_train)\r\n",
    "```\r\n",
    "\r\n",
    "6. **Train and test with sample numeric data**: By using the score function on our pipeline, we can see how our Pipeline performs on the test set. The default scoring method for this classifier is accuracy. That's good enough for our sample dataset.\r\n",
    "\r\n",
    "```python\r\n",
    "accuracy = pl.score(X_test, y_test)\r\n",
    "print('accuracy on numeric data, no nans: ', accuracy)\r\n",
    "```\r\n",
    "\r\n",
    "7. **Adding more steps to the pipeline**: Let's add the with_missing column to our training set. Oops! Now when we call fit, we see a value error that explains that our input has NaN values.\r\n",
    "\r\n",
    "```python\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing']], pd.get_dummies(sample_df['label']), random_state=2)\r\n",
    "pl.fit(X_train, y_train)\r\n",
    "```\r\n",
    "\r\n",
    "8. **Preprocessing numeric features with missing data**: To address this, we'll add an Imputer to our pipeline, which will fill in the NaN values. To do so, we add a step to the Pipeline with the name 'imp' and an Imputer object. The default imputation in scikit-learn is to fill missing values with the mean of the column in question. You can look at the documentation of the Imputer object to see other possible imputation strategies.\r\n",
    "\r\n",
    "```python\r\n",
    "from sklearn.preprocessing import Imputer\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing']], pd.get_dummies(sample_df['label']), random_state=2)\r\n",
    "pl = Pipeline([('imp', Imputer()), ('clf', OneVsRestClassifier(LogisticRegression()))])\r\n",
    "```\r\n",
    "\r\n",
    "9. **Preprocessing numeric features with missing data**: We can call fit and score on the new pipeline, just like we did before. But, in this case our model also includes the column with_missing which had NaN values that were imputed.\r\n",
    "\r\n",
    "```python\r\n",
    "pipeline.fit(X_train, y_train)\r\n",
    "accuracy = pl.score(X_test, y_test)\r\n",
    "print('accuracy on all numeric, incl nans: ', accuracy)\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b9581-3f9a-4341-bda2-3d7eba8a3a9d",
   "metadata": {},
   "source": [
    "### Instantiate pipeline\r\n",
    "\r\n",
    "In order to make your life easier as you start to work with all of the data in your original DataFrame, `df`, it's time to turn to one of scikit-learn's most useful objects: the `Pipeline`.\r\n",
    "\r\n",
    "For the next few exercises, you'll reacquaint yourself with pipelines and train a classifier on some synthetic (sample) data of multiple datatypes before using the same techniques on the main dataset.\r\n",
    "\r\n",
    "The sample data is stored in the DataFrame, `sample_df`, which has three kinds of feature data: numeric, text, and numeric with missing values. It also has a label column with two classes, `a` and `b`.\r\n",
    "\r\n",
    "In this exercise, your job is to instantiate a pipeline that trains using the `numeric` column of the sample data.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Import `Pipeline` from `sklearn.pipeline`.\r\n",
    "- Create training and test sets using the numeric data only. Do this by specifying `sample_df[['numeric']]` in `train_test_split()`.\r\n",
    "- Instantiate a pipeline as pl by adding the classifier step. Use a name of `'clf'` and the same classifier from Chapter 2: `OneVsRestClassifier(LogisticRegression())`.\r\n",
    "- Fit your pipeline to the training data and compute its accuracy to see it in action! Since this is toy data, you'll use the default scoring method for now. In the next chapter, you'll return to log loss scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf2527ea-e93b-4ce5-84ab-90e69008de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('data/2024-01-19_school_budgeting_with_machine_learning_in_python/sample_df.csv')\n",
    "\n",
    "sample_df['text'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e50ae90-12f6-4532-ae56-464828c8e31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on sample data - numeric, no nans:  0.62\n"
     ]
    }
   ],
   "source": [
    "# Split and select numeric data only, no nans \n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric']], pd.get_dummies(sample_df['label']),  random_state=22)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([('clf', OneVsRestClassifier(LogisticRegression()))])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"Accuracy on sample data - numeric, no nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e3fc7-5908-4b3e-8685-bbd7afcbbd6e",
   "metadata": {},
   "source": [
    "**Now it's time to incorporate numeric data with missing values by adding a preprocessing step!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cfccfe-8a5c-4a77-a1fb-d18f053f8ab6",
   "metadata": {},
   "source": [
    "### Preprocessing numeric features\r\n",
    "\r\n",
    "What would have happened if you had included the with `'with_missing'` column in the last exercise? Without imputing missing values, the pipeline would **not** be happy (try it and see). So, in this exercise you'll improve your pipeline a bit by using the `Imputer()` imputation transformer from scikit-learn to fill in missing values in your sample data.\r\n",
    "\r\n",
    "By default, the [imputer transformer][1] replaces NaNs with the mean value of the column. That's a good enough imputation strategy for the sample data, so you won't need to pass anything extra to the imputer.\r\n",
    "\r\n",
    "After importing the transformer, you will edit the steps list used in the previous exercise by inserting a `(name, transform)` tuple. Recall that steps are processed sequentially, so make sure the new tuple encoding your preprocessing step is put in the right place.\r\n",
    "\r\n",
    "The `sample_df` is in the workspace, in case you'd like to take another look. Make sure to select **both** numeric columns- in the previous exercise we couldn't use `with_missing` because we had no preprocessing step!\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Import `Imputer` from `sklearn.preprocessing`.\r\n",
    "- Create training and test sets by selecting the correct subset of `sample_df`: `numeric` and `with_missing`.\r\n",
    "- Add the tuple `('imp', Imputer())` to the correct position in the pipeline. `Pipeline` processes steps sequentially, so the imputation step should come __before__ the classifier step.\r\n",
    "- Complete the `.fit()` and `.score()` methods to fit the pipeline to the data and compute the accuracy.\r\n",
    "\r\n",
    "[1]: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e778c2e-db1d-4cab-99ce-d79784497263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on sample data - all numeric, incl nans:  0.636\n"
     ]
    }
   ],
   "source": [
    "# Create training and test sets using only numeric data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "\n",
    "# Insantiate Pipeline object: pl\n",
    "pl = Pipeline([('imp', SimpleImputer()), ('clf', OneVsRestClassifier(LogisticRegression()))])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"Accuracy on sample data - all numeric, incl nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d329b86a-7f73-4f5f-b1ca-d078cab6c63b",
   "metadata": {},
   "source": [
    "**Now you know how to use preprocessing in pipelines with numeric data, and it looks like the accuracy has improved because of it! Text data preprocessing is next!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b418a9f-9474-488e-8977-6d57ad98d868",
   "metadata": {},
   "source": [
    "## Test features and feature union\r\n",
    "\r\n",
    "1. **Text features and feature unions**: In this video, we'll look at how we process text data in a pipeline and then how we put it all together.\r\n",
    "\r\n",
    "2. **Preprocessing text features**: Our sample dataframe contains one column we haven't used yet, the text column. First, we'll change our train and test data just to be working with the text data for now. Then, we'll add a step to our Pipeline with the name vec and the CountVectorizer object from scikit-learn. Now our pipeline will use the CountVectorizer on our dataset, and then it will pass the result into our classifier.\r\n",
    "\r\n",
    "```python\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df['text'], pd.get_dummies(sample_df['label']), random_state=2)\r\n",
    "pl = Pipeline([('vec', CountVectorizer()), ('clf', OneVsRestClassifier(LogisticRegression()))])\r\n",
    "```\r\n",
    "\r\n",
    "3. **Preprocessing text features**: Again, we can call the fit and score methods on the Pipeline. The score function now reports our accuracy if we just use the text data.\r\n",
    "\r\n",
    "```python\r\n",
    "pl.fit(X_train, y_train)\r\n",
    "\r\n",
    "accuracy = pl.score(X_test, y_test)\r\n",
    "print('accuracy on sample data: ', accuracy)\r\n",
    "```\r\n",
    "\r\n",
    "4. **Preprocessing multiple dtypes**: Let's say we want to use all of our data in a single pipeline. We can't just have a Pipeline that has a `CountVectorizer` step, Imputation step, and then a classifier. The `CountVectorizer` won't know what to do with the numeric columns, and we don't want to perform imputation on the text columns. In order to build our pipeline, we need to separately operate on the text columns and on the numeric columns. There are two tools: FunctionTransformer and FeatureUnion that will help us build a Pipeline to work with both our text and numeric data. The first utility that we cover is the FunctionTransformer.\r\n",
    "- Want to use all available features in one pipeline\r\n",
    "- Problem\r\n",
    "  - Pipeline steps for numeric and text preprocessing can't follow each other\r\n",
    "  - e.g., output of `CountVectorizer` can't be input to `Imputer`\r\n",
    "- Solution\r\n",
    "  - `FunctionTransformer()` & `FeatureUnion()`\r\n",
    "\r\n",
    "5. **FunctionTransformer**: `FunctionTransformer` has a simple job: take a Python function, and turn it into an object that the scikit-learn Pipeline can understand. We'll write two simple functions: one that takes the whole dataframe, and returns just the numeric columns. The other will take the whole dataframe and return just the text columns. Using these function transformers, we can build a separate Pipeline for our numeric data and for our text data.\r\n",
    "- Turns a Python function into an object that a scikit-learn pipeline can understand\r\n",
    "- Need to write two functions for pipeline preprocessing\r\n",
    "  - Take entire DataFrame, return numeric columns\r\n",
    "  - Take entire DataFrame, return text columns\r\n",
    "- Can then preprocess numeric and text data in separate pipelines\r\n",
    "\r\n",
    "6. **Putting it all together**: First, we'll do our train_test split on the entire dataset and import the FunctionTransformer and FeatureUnion utilities.\r\n",
    "\r\n",
    "```python\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric','with_missing', 'text']], pd.get_dummies(sample_df['label']), random_state=2)\r\n",
    "\r\n",
    "from sklearn.preprocessing import FunctionTransformer\r\n",
    "from sklearn.pipeline import FeatureUnion\r\n",
    "```\r\n",
    "\r\n",
    "7. **Putting it all together**: Next, we'll create two `FunctionTransformer` objects. The first takes a dataframe and just returns the column named 'text'. The second takes a dataframe and returns the columns named 'numeric' and 'with_missing'. These two function transformer objects will let us set up separate Pipelines that operate on the selected columns only. Note that we've passed the parameter validate equals False. This simply tells scikit-learn it doesn't need to check for NaNs or validate the dtypes of the input. We'll do that work ourselves.\r\n",
    "\r\n",
    "```python\r\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\r\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['numeric', 'with_missing']], validate=False)\r\n",
    "```\r\n",
    "\r\n",
    "8. **FeatureUnion Text and Numeric Features**: `FeatureUnion` from the sklearn dot pipeline module is the other utility we need. We know that our text pipeline generates the array on the left, our text features.\r\n",
    "\r\n",
    "9. **FeatureUnion Text and Numeric Features**: And our numeric pipeline generates the array on the right, our numeric features.\r\n",
    "\r\n",
    "10. **FeatureUnion Text and Numeric Features**: The FeatureUnion object puts these two sets of features together as a single array that will be the input to our classifier.\r\n",
    "\r\n",
    "```python\r\n",
    "from sklearn.pipeline import FeatureUnion\r\n",
    "union = FeatureUnion([('numeric', numeric_pipeline), ('text', text_pipeline)])\r\n",
    "```\r\n",
    "\r\n",
    "11. **Putting it all together**: Here's our entire pipeline, which processes our text and numeric data. First, we create our separate text and numeric pipelines. Remember, `get_numeric_data` and `get_text_data` are the `FunctionTransformers` that we just created. These pipelines output our numeric features and our text features respectively. Then we create our overall pipeline, which has two steps: First, the `FeatureUnion` takes a list of objects, calls each one, and then concatenates the output into a wide array out of all the results. In this case, it will call our numeric pipeline and then our text pipeline. Once we have this array of all of our features, we can pass it to our classifier. We can call fit and score on this pipeline, just like our simpler ones before it.\r\n",
    "\r\n",
    "```python\r\n",
    "numeric_pipeline = Pipeline([('selector', get_numeric_data), ('imputer', Imputer())])\r\n",
    "text_pipeline = Pipeline([('selector', get_text_data), ('vectorizer', CountVectorizer())])\r\n",
    "pl = Pipeline([('union', FeatureUnion([('numeric', numeric_pipeline), ('text', text_pipeline)])),\r\n",
    "               ('clf', OneVsRestClassifier(LogisticRegression()))])\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3791aa28-417a-45b4-845e-66208018c0a4",
   "metadata": {},
   "source": [
    "### Preprocessing text features\r\n",
    "\r\n",
    "Here, you'll perform a similar preprocessing pipeline step, only this time you'll use the `text` column from the sample data.\r\n",
    "\r\n",
    "To preprocess the text, you'll turn to `CountVectorizer()` to generate a bag-of-words representation of the data, as in Chapter 2. Using the [default][1] arguments, add a `(step, transform)` tuple to the steps list in your pipeline.\r\n",
    "\r\n",
    "Make sure you select only the text column for splitting your training and test sets.\r\n",
    "\r\n",
    "As usual, your `sample_df` is ready and waiting in the workspace.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Import `CountVectorizer` from `sklearn.feature_extraction.tex`t.\r\n",
    "- Create training and test sets by selecting the correct subset of `sample_df`: `'text'`.\r\n",
    "- Add the `CountVectorizer` step (with the name `'vec'`) to the correct position in the pipeline.\r\n",
    "- Fit the pipeline to the training data and compute its accuracy.\r\n",
    "\r\n",
    "[1]: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a5bb903-c8e6-40d0-a85e-9940277aaf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - just text data:  0.808\n"
     ]
    }
   ],
   "source": [
    "# Split out only the text data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df['text'],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('vec', CountVectorizer()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - just text data: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6e626-2b74-4b38-a66e-0db2856c88a1",
   "metadata": {},
   "source": [
    "### Multiple types of processing: FunctionTransformer\r\n",
    "\r\n",
    "The next two exercises will introduce new topics you'll need to make your pipeline truly excel.\r\n",
    "\r\n",
    "Any step in the pipeline must be an object that implements the `fit` and `transform` methods. The [`FunctionTransformer`][1] creates an object with these methods out of any Python function that you pass to it. We'll use it to help select subsets of data in a way that plays nicely with pipelines.\r\n",
    "\r\n",
    "You are working with numeric data that needs imputation, and text data that needs to be converted into a bag-of-words. You'll create functions that separate the text from the numeric variables and see how the `.fit()` and `.transform()` methods work.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Compute the selector `get_text_data` by using a lambda function and `FunctionTransformer()` to obtain all `'text'` columns.\r\n",
    "- Compute the selector `get_numeric_data` by using a lambda function and `FunctionTransformer()` to obtain all the numeric columns (including missing data). These are `'numeric'` and `'with_missing'`.\r\n",
    "- Fit and transform `get_text_data` using the `.fit_transform()` method with `sample_df` as the argument.\r\n",
    "- Fit and transform `get_numeric_data` using the same approach as above.\r\n",
    "\r\n",
    "\r\n",
    "[1]: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e8b01c8-6105-4bff-98cc-69c1273d5b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0           \n",
       "1        foo\n",
       "2    foo bar\n",
       "3           \n",
       "4    foo bar\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numeric</th>\n",
       "      <th>with_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.856306</td>\n",
       "      <td>4.433240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.973454</td>\n",
       "      <td>4.310229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.829785</td>\n",
       "      <td>2.469828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.062947</td>\n",
       "      <td>2.852981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.786003</td>\n",
       "      <td>1.826475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     numeric  with_missing\n",
       "0 -10.856306      4.433240\n",
       "1   9.973454      4.310229\n",
       "2   2.829785      2.469828\n",
       "3 -15.062947      2.852981\n",
       "4  -5.786003      1.826475"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "\n",
    "# Obtain the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['numeric', 'with_missing']], validate=False)\n",
    "\n",
    "# Fit and transform the text data: just_text_data\n",
    "just_text_data = get_text_data.fit_transform(sample_df)\n",
    "\n",
    "# Fit and transform the numeric data: just_numeric_data\n",
    "just_numeric_data = get_numeric_data.fit_transform(sample_df)\n",
    "\n",
    "# Print head to check results\n",
    "print('Text Data')\n",
    "display(just_text_data.head())\n",
    "print('\\nNumeric Data')\n",
    "display(just_numeric_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c59a0d-8836-4885-8785-66303ab6b9b6",
   "metadata": {},
   "source": [
    "### Multiple types of processing: FeatureUnion\r\n",
    "\r\n",
    "Now that you can separate text and numeric data in your pipeline, you're ready to perform separate steps on each by nesting pipelines and using `FeatureUnion()`.\r\n",
    "\r\n",
    "These tools will allow you to streamline all preprocessing steps for your model, even when multiple datatypes are involved. Here, for example, you don't want to impute our text data, and you don't want to create a bag-of-words with our numeric data. Instead, you want to deal with these separately and then join the results together using `FeatureUnion()`.\r\n",
    "\r\n",
    "In the end, you'll still have only two high-level steps in your pipeline: preprocessing and model instantiation. The difference is that the first preprocessing step actually consists of a pipeline for numeric data and a pipeline for text data. The results of those pipelines are joined using `FeatureUnion()`.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- In the `process_and_join_features`:\r\n",
    "  - Add the steps `('selector', get_numeric_data)` and `('imputer', Imputer())` to the `'numeric_features'` preprocessing step.\r\n",
    "  - Add the equivalent steps for the `text_features` preprocessing step. That is, use `get_text_data` and a `CountVectorizer` step with the name `'vectorizer'`.\r\n",
    "- Add the transform step `process_and_join_features` to `'union'` in the main pipeline, `pl`.\r\n",
    "- Hit submit to see the pipeline in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee33d9fa-0f80-43a0-9f7a-acf42a9633d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - all data:  0.928\n"
     ]
    }
   ],
   "source": [
    "# Split using ALL data in sample_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing', 'text']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', SimpleImputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all data: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094f7db-b88f-49bc-bede-fa634fa0c411",
   "metadata": {},
   "source": [
    "## Choosing a classification model\r\n",
    "\r\n",
    "1. **Choosing a classification model**: Now that we understand how to pull together text and numeric data into a single machine learning pipeline, we'll return to talking about our school budget dataset. In the sample dataset, there was only one text column. This is the format that `CountVectorizer` expects.\r\n",
    "\r\n",
    "2. **Main dataset: lots of text**: However, our main dataset has 14 text columns. In an interactive exercise during our NLP chapter we wrote a function combine_text_columns that put together all the text columns into a single column. We'll re-use this function as part of our Pipeline to process the text in the budget dataset.\r\n",
    "\r\n",
    "```python\r\n",
    "LABELS = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status']\r\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\r\n",
    "len(NON_LABELS) - len(NUMERIC_COLUMNS)\r\n",
    "```\r\n",
    "\r\n",
    "3. **Using pipeline with the main dataset**: Again, as we did in the last chapter, we'll use the `get_dummies` function from pandas to create our label array, and we'll also create our train-test split using the `multilabel_train_test_split` function. Hopefully, this is starting to feel familiar.\r\n",
    "\r\n",
    "4. **Using pipeline with the main dataset**: Now we'll create a pipeline for working with our main dataset. The beauty of this code, is that it has one change from the code we used for the sample dataset: we create a `FunctionTransformer` object using our combine_text_columns function instead of the simple selection function we used in the sample dataset. Other than this one change, the pipeline that processes the text, imputes the numeric columns, joins those results together and then fits a multilabel logistic regression remains the same.\r\n",
    "\r\n",
    "```python\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "df = pd.read_csv('TrainingSetSample.csv', index_col=0)\r\n",
    "dummy_labels = pd.get_dummies(df[LABELS])\r\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(\r\n",
    "    df[NON_LABELS], dummy_labels,\r\n",
    "    0.2)\r\n",
    "\r\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\r\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\r\n",
    "pl = Pipeline([\r\n",
    "    ('union', FeatureUnion([\r\n",
    "        ('numeric_features', Pipeline([\r\n",
    "            ('selector', get_numeric_data),\r\n",
    "            ('imputer', Imputer())\r\n",
    "        ])),\r\n",
    "        ('text_features', Pipeline([\r\n",
    "            ('selector', get_text_data),\r\n",
    "            ('vectorizer', CountVectorizer())\r\n",
    "        ]))\r\n",
    "    ])\r\n",
    "     ),\r\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression()))\r\n",
    "])\r\n",
    "```\r\n",
    "\r\n",
    "5. **Performance using main dataset**: We can now fit this Pipeline on the school budget dataset. As part of our exercises, we'll look at the results of this pipeline. Now we have infrastructure for processing our features and fitting a model. This infrastructure allows us to easily experiment with adapting different parts of the pipeline. Part of your challenge in the exercises will be to improve the performance of the pipeline.\r\n",
    "\r\n",
    "```python\r\n",
    "pl.fit(X_train, y_train)\r\n",
    "```\r\n",
    "\r\n",
    "6. **Flexibility of model step**: For example, we can easily experiment with different classes of models. All of our Pipeline code can stay the same, but we can update the last step to be a different class of model instead of `LogisticRegression`. For example, we could try a `RandomForestClassifier`, `NaiveBayesClassifier`, or a `KNeighborsClassifier` instead. In fact, you can look at the scikit-learn documentation and choose any model class you want!\r\n",
    "- Is current model the best?\r\n",
    "- Can quickly try different models with pipelines\r\n",
    "  - Pipeline preprocessing steps unchanged\r\n",
    "  - Edit the model step in your pipeline\r\n",
    "  - Random Forest, Naive Bayes, k-NN\r\n",
    "\r\n",
    "7. **Easily try new models using pipeline**: Here's an example of how simple it is to change the classification method in our scikit-learn Pipeline. We simply import a different class of model--in this case, we'll use a `RandomForestClassifier`. Then, the only other line that needs to change is the one that defines the classifier inside the Pipeline. This makes it very simple for us to try a large number of different model classes and determine which one is the best for the problem that we're working on.\r\n",
    "\r\n",
    "```python\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "pl = Pipeline([\r\n",
    "    ('union', FeatureUnion(\r\n",
    "        transformer_list=[\r\n",
    "            ('numeric_features', Pipeline([\r\n",
    "                ('selector', get_numeric_data),\r\n",
    "                ('imputer', Imputer())\r\n",
    "            ])),\r\n",
    "            ('text_features', Pipeline([\r\n",
    "                ('selector', get_text_data),\r\n",
    "                ('vectorizer', CountVectorizer())\r\n",
    "            ]))\r\n",
    "        ]\r\n",
    "    )),\r\n",
    "    ('clf', OneVsRest(RandomForestClassifier()))\r\n",
    "])\r\n",
    "```\r\n",
    "\r\n",
    "8. **Let's practice**: Now your task is to implement the classification pipeline on the school budget dataset. You will also get the chance to experiment with the Pipeline steps and model class. See how much you can improve the performance of the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7630fa-b210-4e3e-af80-195ad51a036e",
   "metadata": {},
   "source": [
    "### Using FunctionTransformer on the main dataset\r\n",
    "\r\n",
    "In this exercise you're going to use `FunctionTransformer` on the primary budget data, before instantiating a multiple-datatype pipeline in the next exercise.\r\n",
    "\r\n",
    "Recall from Chapter 2 that you used a custom function `combine_text_columns` to select and properly format **text data** for tokenization; it is loaded into the workspace and ready to be put to work in a function transformer!\r\n",
    "\r\n",
    "Concerning the **numeric data**, you can use `NUMERIC_COLUMNS`, preloaded as usual, to help design a subset-selecting lambda function.\r\n",
    "\r\n",
    "You're all finished with sample data. The original `df` is back in the workspace, ready to use.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Complete the call to `multilabel_train_test_split()` by selecting `df[NON_LABELS]`.\r\n",
    "- Compute `get_text_data` by using `FunctionTransformer()` and passing in `combine_text_columns`. Be sure to also specify `validate=False`.\r\n",
    "- Use `FunctionTransformer()` to compute `get_numeric_data`. In the lambda function, select out the `NUMERIC_COLUMNS` of `x`. Like you did when computing `get_text_data`, also specify `validate=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1499b850-5879-48fb-a124-53a80461f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2024-01-19_school_budgeting_with_machine_learning_in_python/TrainingData.csv', index_col=0)\n",
    "LABELS_td = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status']\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "df[LABELS_td] = df[LABELS_td].apply(categorize_label)\n",
    "NUMERIC_COLUMNS_td = df.select_dtypes(include='number').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e405cbc-73e6-477c-89df-4af790bf0cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\users\\trenton\\Dropbox\\PythonProjects\\DataCamp\\functions\\multilabel.py:31: UserWarning: Size less than number of columns * min_count, returning 520 items instead of 312.0.\n",
      "  warn(msg.format(y.shape[1] * min_count, size))\n"
     ]
    }
   ],
   "source": [
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(df[LABELS_td])\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS_td]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS_td], validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa6948-164a-44a6-b7ca-b1413af9f703",
   "metadata": {},
   "source": [
    "### Add a model to the pipeline\r\n",
    "\r\n",
    "You're about to take everything you've learned so far and implement it in a `Pipeline` that works with the real, [DrivenData][1] budget line item data you've been exploring.\r\n",
    "\r\n",
    "**Surprise!** The structure of the pipeline is exactly the same as earlier in this chapter:\r\n",
    "\r\n",
    "- the **preprocessing step** uses `FeatureUnion` to join the results of nested pipelines that each rely on `FunctionTransformer` to select multiple datatypes\r\n",
    "- the **model step** stores the model object\r\n",
    "\r\n",
    "- You can then call familiar methods like `.fit()` and `.score()` on the `Pipeline` object `pl`.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Complete the `'numeric_features'` transform with the following steps:\r\n",
    "  - `get_numeric_data`, with the name `'selector'`.\r\n",
    "  - `Imputer()`, with the name `'imputer'`.\r\n",
    "- Complete the `'text_features'` transform with the following steps:\r\n",
    "  - `get_text_data`, with the name `'selector'`.\r\n",
    "  - `CountVectorizer()`, with the name `'vectorizer'`.\r\n",
    "- Fit the pipeline to the training data.\r\n",
    "- Hit submit to compute the accuracy!\r\n",
    "\r\n",
    "\r\n",
    "[1]: https://www.drivendata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a898a53-93fc-4bf8-bb3b-bd824949bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Complete the pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', SimpleImputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression(max_iter=1000)))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f1868-9786-4dba-bcad-fb76a052b4ba",
   "metadata": {},
   "source": [
    "**Now that you've built the entire pipeline, you can easily start trying out different models by just modifying the `'clf'` step.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cfec0-a466-4e82-891a-58060b5d3443",
   "metadata": {},
   "source": [
    "### Try a different class of model\r\n",
    "\r\n",
    "Now you're cruising. One of the great strengths of pipelines is how easy they make the process of testing different models.\r\n",
    "\r\n",
    "Until now, you've been using the model step `('clf', OneVsRestClassifier(LogisticRegression()))` in your pipeline.\r\n",
    "\r\n",
    "But what if you want to try a different model? Do you need to build an entirely new pipeline? New nests? New FeatureUnions? Nope! You just have a simple one-line change, as you'll see in this exercise.\r\n",
    "\r\n",
    "In particular, you'll swap out the logistic-regression model and replace it with a [random forest][1] classifier, which uses the statistics of an ensemble of decision trees to generate predictions.\r\n",
    "\r\n",
    "**Instructions**\r\n",
    "\r\n",
    "- Import the `RandomForestClassifier` from `sklearn.ensemble`.\r\n",
    "- Add a `RandomForestClassifier()` step named `'clf'` to the pipeline.\r\n",
    "- Hit submit to fit the pipeline to the training data and compute its accuracy.\r\n",
    "\r\n",
    "\r\n",
    "[1]: https://en.wikipedia.org/wiki/Random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4717873b-25bc-4800-8bca-96f90cc07179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.3211538461538462\n"
     ]
    }
   ],
   "source": [
    "# Edit model step in pipeline\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', SimpleImputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier(n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2afe7-9dfe-4b47-aa04-1c6fd2c99604",
   "metadata": {},
   "source": [
    "**An accuracy improvement- amazing! All your work building the pipeline is paying off. It's now very simple to test different models!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09bcf191-ec06-4e2c-9513-c32c1fbe4f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.29423076923076924\n"
     ]
    }
   ],
   "source": [
    "# Edit model step in pipeline\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', SimpleImputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier(n_estimators=15, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f5449-be8f-4f0b-b392-ce01fe66d4a1",
   "metadata": {},
   "source": [
    "**It's time to get serious and work with the log loss metric. You'll learn expert techniques in the next chapter to take the model to the next level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01633607-7f98-46fc-a655-5c815e269770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
